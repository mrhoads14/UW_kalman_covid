{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs an extended Kalman filter on Prof Flaxman's SEIIR predictions and\n",
    "measurement data for New York State from mid-April to 7 July 2020.\n",
    "\n",
    "S - Susceptible\n",
    "E - Exposed\n",
    "I1 - Presymptomatic\n",
    "I2 - Symptomatic\n",
    "R - Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_sets_wDeaths\n",
    "import seiir_compartmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to support the Kalman filtering\n",
    "def get_predicts_prior(day, seiir):\n",
    "    x_hat = np.array([[seiir['S'].loc[day]],\n",
    "                      [seiir['E'].loc[day]],\n",
    "                      [seiir['I1'].loc[day]],\n",
    "                      [seiir['I2'].loc[day]],\n",
    "                      [seiir['R'].loc[day]],\n",
    "                      [10**-10]])\n",
    "\n",
    "    beta_k = seiir['beta_pred'].loc[day]\n",
    "\n",
    "    return x_hat, beta_k\n",
    "\n",
    "\n",
    "def step_seiir(x_hat, constants, beta_k, days=7):\n",
    "    s_dict = {'S': x_hat[0, 0],\n",
    "              'E': x_hat[1, 0],\n",
    "              'I1': x_hat[2, 0],\n",
    "              'I2': x_hat[3, 0],\n",
    "              'R': x_hat[4, 0]}\n",
    "\n",
    "    s = pd.Series(s_dict)\n",
    "\n",
    "    for i in range(days):\n",
    "        infectious = s.loc['I1'] + s.loc['I2']\n",
    "        s = seiir_compartmental.compartmental_covid_step(s, s.sum(),\n",
    "                                                         infectious,\n",
    "                                                         constants['alpha'],\n",
    "                                                         beta_k,\n",
    "                                                         constants['gamma1'],\n",
    "                                                         constants['gamma2'],\n",
    "                                                         constants['sigma'],\n",
    "                                                         constants['theta'])\n",
    "    x_hat_future_prior = np.array([[s.loc['S']],\n",
    "                                   [s.loc['E']],\n",
    "                                   [s.loc['I1']],\n",
    "                                   [s.loc['I2']],\n",
    "                                   [s.loc['R']],\n",
    "                                   [x_hat[5,0]]])\n",
    "\n",
    "    return x_hat_future_prior\n",
    "\n",
    "\n",
    "def predict_step(x_hat_k1_prior, P, Q, beta_k, constants):\n",
    "    S = x_hat_k1_prior[0, 0]\n",
    "    E = x_hat_k1_prior[1, 0]\n",
    "    I1 = x_hat_k1_prior[2, 0]\n",
    "    I2 = x_hat_k1_prior[3, 0]\n",
    "    R = x_hat_k1_prior[4, 0]\n",
    "    N = S + E + I1 + I2 + R\n",
    "    alpha = constants['alpha']\n",
    "    sigma = constants['sigma']\n",
    "    gamma1 = constants['gamma1']\n",
    "    gamma2 = constants['gamma2']\n",
    "\n",
    "    part_f_S = np.array([[-beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_E = np.array([[0],\n",
    "                         [-sigma],\n",
    "                         [sigma],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_I1 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [-gamma1],\n",
    "                          [gamma1],\n",
    "                          [0],\n",
    "                          [0]])\n",
    "\n",
    "    part_f_I2 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [0],\n",
    "                          [-gamma2],\n",
    "                          [gamma2],\n",
    "                          [0]])\n",
    "\n",
    "    part_f_R = np.array([[0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "    \n",
    "    extra = np.array([[0],\n",
    "                      [0],\n",
    "                      [0],\n",
    "                      [0],\n",
    "                      [0],\n",
    "                      [0]])\n",
    "\n",
    "    # 6x6\n",
    "    f_jacob = np.concatenate([part_f_S, part_f_E, part_f_I1, part_f_I2,\n",
    "                              part_f_R, extra], axis=1)\n",
    "\n",
    "    # 6x6\n",
    "    # P_k1_prior = f_jacob * P * f_jacob^T + Q\n",
    "    P_k1_prior = np.matmul(np.matmul(f_jacob, P), np.transpose(f_jacob)) + Q\n",
    "    return P_k1_prior\n",
    "\n",
    "\n",
    "def update_step(x_hat, x_hat_k1, P_k1, Rn, rho1, rho2, z_k):\n",
    "    # 6x6\n",
    "    ep = 10**-10\n",
    "    H = np.array([[ep, 0, 0, 0, 0, 0],\n",
    "                  [0, ep, 0, 0, 0, 0],\n",
    "                  [0, 0, ep, rho1, 0, 0],\n",
    "                  [0, 0, 0, rho2, 0, 0],\n",
    "                  [0, 0, 0, 0, ep, 0],\n",
    "                  [0, 0, 0, rho3, 0, ep]])\n",
    "    #H = np.array([[0, 0, 0, 0, 0],\n",
    "    #                  [0, 0, 0, 0, 0],\n",
    "    #                  [0, 0, 0, rho1, 0],\n",
    "    #                  [0, 0, 0, rho2, 0],\n",
    "    #                  [0, 0, 0, 0, 0]])\n",
    "    \n",
    "    # Si = H * P_k1 * H^T + Rn\n",
    "    Si = np.matmul(np.matmul(H, P_k1), np.transpose(H)) + Rn\n",
    "\n",
    "    # K_new = P_k1 * H^T * Si^(-1)\n",
    "    K_new = np.matmul(np.matmul(P_k1, np.transpose(H)), np.linalg.inv(Si))\n",
    "    y_new = np.matmul(H, x_hat)\n",
    "\n",
    "    # 6x1\n",
    "    diff = z_k - y_new\n",
    "\n",
    "    x_hat_k1_post = x_hat_k1 + np.matmul(K_new, diff)\n",
    "\n",
    "    P_k1_post = P_k1 - np.matmul(np.matmul(K_new, Si), np.transpose(K_new))\n",
    "\n",
    "    # joseph formulation\n",
    "    #joe2 = np.matmul(np.matmul(K_new, Rn), np.transpose(K_new))\n",
    "    #joe1 = np.eye(5) - np.matmul(K_new, H)\n",
    "    #P_k1_post = np.matmul(np.matmul(joe1, P_k1), np.transpose(joe1)) - joe2\n",
    "\n",
    "    return x_hat_k1_post, P_k1_post\n",
    "\n",
    "def get_predict_measures():\n",
    "    predictions = pd.read_csv(\n",
    "        r'case_vs_symptom/kalman/predicted_measures/predictions.csv',\n",
    "        header=None, names=['measure_date', 'prediction_date', 'prop', 'case',\n",
    "                            'prop_pred7', 'case_pred7', 'prop_pred1',\n",
    "                            'case_pred1'],\n",
    "        index_col=False, usecols=[0, 4, 5])\n",
    "\n",
    "    start_d = datetime.timedelta(days=int(predictions['measure_date'].iloc[0]))\n",
    "    start = datetime.date(2019, 12, 31) + start_d\n",
    "    end_d = datetime.timedelta(days=int(predictions['measure_date'].iloc[-1]))\n",
    "    end = datetime.date(2019, 12, 31) + end_d\n",
    "\n",
    "    measure_rng = pd.date_range(start=start, end=end)\n",
    "\n",
    "    # code to save:\n",
    "    # prediction_rng = pd.date_range(start=datetime.date(2019, 12, 31) +\n",
    "    # datetime.timedelta(days=int(predictions['prediction_date'].iloc[0])),\n",
    "    # end=datetime.date(2019, 12, 31) +\n",
    "    # datetime.timedelta(days=int(predictions['prediction_date'].iloc[-1])))\n",
    "\n",
    "    predictions.set_index(measure_rng, inplace=True)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_data_sets(state, fips=None):\n",
    "    # the post hoc seiir model predictions provided by Prof Flaxman without\n",
    "    # any kalman filtering:\n",
    "    #seiir = pd.read_csv(r'data/seiir_compartments_post-hoc_ny_state_20200910.csv', header=0,\n",
    "    #                    index_col='date', parse_dates=True)\n",
    "    seiir = pd.read_csv(r'data/seiir_compartments_post-hoc_ny_state.csv', header=0,\n",
    "                        index_col='date', parse_dates=True)\n",
    "    \n",
    "\n",
    "    fb_data = data_sets_wDeaths.create_symptom_df()\n",
    "    fb_data_val = data_sets_wDeaths.create_symptom_df(valid=True)\n",
    "\n",
    "    if fips is None:\n",
    "        case_data = data_sets_wDeaths.create_case_df_state()\n",
    "        case_data_geo = case_data.loc[state][['case_rate', 'death_rate']].copy()\n",
    "        fb_data_geo = fb_data.loc[state].groupby('date').sum().copy()\n",
    "        fb_data_val_geo = fb_data_val.loc[state].groupby('date').sum().copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        case_data = data_sets_wDeaths.create_case_df_county()\n",
    "        case_data_geo = case_data.loc[fips][['case_rate', 'death_rate']].copy()\n",
    "\n",
    "        if fips == 'New York City':\n",
    "            nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "            fb_data_geo = fb_data.loc[(slice(None), '36081'), :].copy()\n",
    "            fb_data_geo = fb_data_geo.mean(level='date')\n",
    "            fb_data_val_geo = fb_data_val.loc[(slice(None), '36081'), :].copy()\n",
    "            fb_data_val_geo = fb_data_val.mean(level='date')\n",
    "            for borough in nyc_fips:\n",
    "                fb_data_geo += fb_data.loc[(slice(None), borough), :].copy().mean(level='date')\n",
    "                fb_data_val_geo += fb_data_val.loc[(slice(None), borough), :].copy().mean(level='date')\n",
    "        else:\n",
    "            fb_data_geo = fb_data.loc[(slice(None), fips), :].copy()\n",
    "            fb_data_val_geo = fb_data_val.loc[(slice(None), fips), :].copy()\n",
    "            # collapse down to a single index column (date)\n",
    "            fb_data_geo = fb_data_geo.mean(level='date')\n",
    "            fb_data_val_geo = fb_data_val_geo.mean(level='date')\n",
    "\n",
    "    return seiir, fb_data_geo, fb_data_val_geo, case_data_geo\n",
    "\n",
    "\n",
    "def calc_fb_ma7(fb_data):\n",
    "    \"\"\"\n",
    "    Returns a Pandas series\n",
    "    \"\"\"\n",
    "    # the fb_data is a DataFrame while the case_data is a Series\n",
    "    fb_ma7 = fb_data.rolling(window=7).mean()\n",
    "    fb_ma7 = fb_ma7.iloc[6:, :]\n",
    "    prop_ma7 = fb_ma7['num_stl'].div(fb_ma7['n'])\n",
    "\n",
    "    return prop_ma7, fb_ma7['n'].copy(), fb_ma7['num_stl'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set constants\n",
    "K0 = datetime.date(2020, 4, 12)\n",
    "\n",
    "the_state = 'NY'\n",
    "the_county = 'New York City'\n",
    "#the_county = data_sets_wDeaths.get_fips('NY', 'Westchester')\n",
    "constants = {\n",
    "    'alpha': 0.948786,\n",
    "    'gamma1': 0.500000,\n",
    "    'gamma2': 0.662215,\n",
    "    'sigma': 0.266635,\n",
    "    'theta': 6.000000\n",
    "    }\n",
    "\n",
    "# set initial values for Kalman filter parameters\n",
    "P_mult = 1\n",
    "Q_mult = 1\n",
    "\n",
    "# Rn is the R noise matrix; it remains constant thru the stepping of the\n",
    "# Kalman filter\n",
    "# prior to experiments, Rn_mult = 5*10**-4\n",
    "Rn_mult = 5*10**-8\n",
    "\n",
    "Rn_22 = 88\n",
    "Rn_32 = 150\n",
    "\n",
    "Rn_23 = 0\n",
    "Rn_33 = 1\n",
    "\n",
    "Rn_52 = 600\n",
    "\n",
    "Rn = Rn_mult * np.array([[0, 0, 0, 0, 0, 0],\n",
    "                         [0, 0, 0, 0, 0, 0],\n",
    "                         [0, 0, Rn_22, Rn_23, 0, 0],\n",
    "                         [0, 0, Rn_32, Rn_33, 0, 0],\n",
    "                         [0, 0, 0, 0, 0, 0],\n",
    "                         [0, 0, Rn_52, 0, 0, 0]])\n",
    "Q = Q_mult * np.eye(6)\n",
    "P = P_mult * np.eye(6)\n",
    "\n",
    "# generate data\n",
    "seiir, fb_data, fb_data_val, case_data = get_data_sets(\n",
    "    data_sets_wDeaths.STATES[the_state], fips=the_county)\n",
    "\n",
    "if the_county == 'New York City':\n",
    "    county_pop = 0\n",
    "    for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "        this_count, state_pop = data_sets.get_pops(each)\n",
    "        county_pop += this_count\n",
    "else:\n",
    "    county_pop, state_pop = data_sets.get_pops(the_county)\n",
    "\n",
    "b = county_pop / state_pop\n",
    "\n",
    "# calculate moving averages on the fb and case data\n",
    "case_ma7 = case_data['case_rate'].rolling(window=7).mean()\n",
    "case_ma7_all = case_ma7.iloc[6:]\n",
    "case_data['death_rate'][case_data['death_rate'] < 0] = 0\n",
    "deaths_ma28 = case_data['death_rate'].rolling(window=28).mean()\n",
    "deaths_ma28_all = deaths_ma28.iloc[27:]\n",
    "\n",
    "prop_ma7, n_ma7, num_stl_ma7 = calc_fb_ma7(fb_data)\n",
    "prop_ma7_valid, n_ma7_valid, num_stl_ma7_valid = calc_fb_ma7(fb_data_val)\n",
    "\n",
    "\n",
    "# get starting compartment values for the state level\n",
    "x_hat_state_k0, beta_k0 = get_predicts_prior(K0, seiir)\n",
    "# convert to county values:\n",
    "x_hat_k0 = b * x_hat_state_k0\n",
    "# set the death rate value in the county x vector\n",
    "x_hat_k0[5,0] = deaths_ma28_all.loc[K0]\n",
    "I2_county = x_hat_k0[3, 0]\n",
    "\n",
    "rho1 = prop_ma7.loc['2020-04-12'] / I2_county\n",
    "rho2 = case_ma7_all.loc['2020-04-12'] / I2_county\n",
    "rho3 = 0.06 * rho2\n",
    "\n",
    "\n",
    "# approximate rho values\n",
    "# I2_county = b * I2\n",
    "# prop_county = rho1 * I2_county\n",
    "# case_county = rho2 * I2_county\n",
    "\n",
    "\n",
    "# create empty dictionaries to hold the estimated values\n",
    "prop_est = {}\n",
    "case_est = {}\n",
    "seiir_pred = {}\n",
    "death_est = {}\n",
    "\n",
    "\n",
    "x_death = deaths_ma28_all.loc[K0]\n",
    "\n",
    "# Original data run ----------------\n",
    "start = K0\n",
    "d = start\n",
    "while d <= datetime.date(2020, 9, 30):\n",
    "    # each cycle of the while loop executes a step\n",
    "\n",
    "    # get state level compartments\n",
    "    x_hat_state_k, beta_k = get_predicts_prior(d, seiir)\n",
    "\n",
    "    # step the state level compartments 7 days forward\n",
    "    x_hat_state_k1 = step_seiir(x_hat_state_k, constants, beta_k)\n",
    "\n",
    "    # convert the state level compartments to county level values\n",
    "    x_hat_k = b * x_hat_state_k\n",
    "    #x_hat_k[5, 0] = x_death\n",
    "    x_hat_k1 = b * x_hat_state_k1\n",
    "    #x_hat_k1[5, 0] = x_death\n",
    "\n",
    "    # get measurements\n",
    "    z_k = np.array([[0],\n",
    "                    [0],\n",
    "                    [prop_ma7.loc[d]],\n",
    "                    [case_ma7_all.loc[d]],\n",
    "                    [0],\n",
    "                    [deaths_ma28_all.loc[d]]])\n",
    "\n",
    "    # predict step\n",
    "    P = predict_step(x_hat_k1, P, Q, beta_k, constants)\n",
    "    print('step -----------')\n",
    "    print('P:')\n",
    "    print(P)\n",
    "\n",
    "    # update step\n",
    "    x_hat_post, P_post = update_step(x_hat_k, x_hat_k1, P, Rn,\n",
    "                                     rho1, rho2, z_k)\n",
    "    print('P_post:')\n",
    "    print(P_post)\n",
    "    print('x_hat_post:')\n",
    "    print(x_hat_post)\n",
    "    \n",
    "    # store the posterior death value (we don't have an modeled estimate of it)\n",
    "    #x_death = x_hat_post[5, 0]\n",
    "\n",
    "    # store estimated values for proportion and case rate\n",
    "    indexDate = d + datetime.timedelta(days=7)\n",
    "    prop_est[indexDate] = rho1 * x_hat_post[3, 0]\n",
    "    case_est[indexDate] = rho2 * x_hat_post[3, 0]\n",
    "    seiir_pred[indexDate] = b * x_hat_k1[3, 0]\n",
    "    death_est[indexDate] = x_hat_post[5, 0]\n",
    "\n",
    "    # update the P and d\n",
    "    P = P_post\n",
    "    d += datetime.timedelta(days=1)\n",
    "    \n",
    "# create pandas series of the estimated case rate\n",
    "predicted_case = pd.Series(case_est)\n",
    "predicted_seiir_prior = pd.Series(seiir_pred)\n",
    "predicted_death = pd.Series(death_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_ma28_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASE calculation -----------------\n",
    "\n",
    "left = predicted_case.index[0]\n",
    "right = predicted_case.index[-1]\n",
    "\n",
    "# take error between prediction and actual\n",
    "e = (case_ma7_all.loc[left:right] - predicted_case.loc[left:right]).abs()\n",
    "\n",
    "case_ma7_diff = case_ma7_all.diff(7)\n",
    "denom = (case_ma7_diff.loc[left:right]).abs()\n",
    "\n",
    "term = e.div(denom)\n",
    "term.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "term.dropna(inplace=True)\n",
    "mase = term.sum() / len(term)\n",
    "print('mase:', mase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not currently used ---------------\n",
    "# Validation data run ---------------------\n",
    "start = prop_ma7_valid.index[0]\n",
    "d = start\n",
    "while d <= prop_ma7_valid.index[-1]:\n",
    "    # each cycle of the while loop executes a step\n",
    "\n",
    "    # get state level compartments\n",
    "    x_hat_state_k, beta_k = get_predicts_prior(d, seiir)\n",
    "\n",
    "    # step the state level compartments 7 days forward\n",
    "    x_hat_state_k1 = step_seiir(x_hat_state_k, constants, beta_k)\n",
    "\n",
    "    # convert the state level compartments to county level values\n",
    "    x_hat_k = b * x_hat_state_k\n",
    "    x_hat_k1 = b * x_hat_state_k1\n",
    "\n",
    "    # get measurements\n",
    "    z_k = np.array([[0],\n",
    "                    [0],\n",
    "                    [prop_ma7_valid.loc[d]],\n",
    "                    [case_ma7_all.loc[d]],\n",
    "                    [0]])\n",
    "\n",
    "    # predict step\n",
    "    P = predict_step(x_hat_k1, P, Q, beta_k, constants)\n",
    "    print('step -----------')\n",
    "    print('P:')\n",
    "    print(P)\n",
    "\n",
    "    # update step\n",
    "    x_hat_post, P_post = update_step(x_hat_k, x_hat_k1, P, Rn,\n",
    "                                     rho1, rho2, z_k)\n",
    "    print('P_post:')\n",
    "    print(P_post)\n",
    "\n",
    "    # store estimated values for proportion and case rate\n",
    "    indexDate = d + datetime.timedelta(days=7)\n",
    "    prop_est[indexDate] = rho1 * x_hat_post[3, 0]\n",
    "    case_est[indexDate] = rho2 * x_hat_post[3, 0]\n",
    "    seiir_pred[indexDate] = b * x_hat_k1[3, 0]\n",
    "\n",
    "    # update the P and d\n",
    "    P = P_post\n",
    "    d += datetime.timedelta(days=1)\n",
    "    \n",
    "# create pandas series of the estimated case rate\n",
    "predicted_case = pd.Series(case_est)\n",
    "predicted_seiir_prior = pd.Series(seiir_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting constants and variables ----------------\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "purple = '#33016F'\n",
    "gold = '#9E7A27'\n",
    "gray = '#797979'\n",
    "width = 4\n",
    "%matplotlib qt\n",
    "\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=start, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single plot with all lines\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "tick_start = K0\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "\n",
    "\n",
    "fig3, ax31 = plt.subplots(1)\n",
    "plt.sca(ax31)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Case Positive Rate', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.plot(predicted_case.index, predicted_case, label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "plt.plot(predicted_death.index, predicted_death, label='Death Rate Forecast', c='blue', linewidth=width)\n",
    "plt.plot(deaths_ma28_all.loc[start:d].index, deaths_ma28_all.loc[start:d], label='Death Rate', c='green', linewidth=width)\n",
    "#plt.ylim(-2, 72)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "# plt.xlabel('Date')\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ax32 = ax31.twinx()\n",
    "plt.sca(ax32)\n",
    "plt.plot(prop_ma7.index, num_stl_ma7, c='red', label='Facebook Positive Symptoms',\n",
    "         linewidth=width)\n",
    "#plt.ylim(-.065, 2.5)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "\n",
    "plt.ylabel('Number of Positive Symptom Response per Day')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax41 = plt.subplots(1)\n",
    "plt.plot(predicted_death.index, predicted_death, label='Death Rate Forecast', c='blue')\n",
    "plt.plot(deaths_ma28_all.loc[start:d].index, deaths_ma28_all.loc[start:d], label='Death Rate', c='green')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not currently used ---------------------\n",
    "# plot validation data\n",
    "\n",
    "fig_v, ax_v = plt.subplots(1)\n",
    "plt.sca(ax_v)\n",
    "\n",
    "\n",
    "plt.plot(case_ma7_all.loc[start:end].index, case_ma7_all.loc[start:end], label='Case Positive Rate', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.plot(predicted_case.index, predicted_case, label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "#plt.ylim(-2, 72)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "# plt.xlabel('Date')\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ax32 = ax_v.twinx()\n",
    "plt.sca(ax32)\n",
    "plt.plot(prop_ma7_valid.index, 100*prop_ma7_valid, c='red', label='Facebook Symptom Rate',\n",
    "         linewidth=width)\n",
    "plt.ylim(-.065, 2.5)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "\n",
    "plt.ylabel('Percentage of Positive Symptom Response')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compute squared error for the overlapping time period\n",
    "overlap = pd.date_range(start='2020-04-19', end='2020-07-07')\n",
    "overlap_dt = [x.to_pydatetime().date() for x in overlap]\n",
    "\n",
    "# error between the measured case rate (smoothed) and the\n",
    "# SEIIR model scaled to the county (without any Kalman adjustment)\n",
    "seiir_sq_err = 0\n",
    "\n",
    "# error between the measured case rate (smoothed) and the predicted\n",
    "# output of the Kalman filter\n",
    "kalman_sq_err = 0\n",
    "\n",
    "for day in overlap_dt:\n",
    "    seiir_sq_err += (case_ma7_all[day] - predicted_seiir_prior[day])**2\n",
    "    kalman_sq_err += (predicted_case[day] - case_ma7_all[day])**2\n",
    "\n",
    "print('SSE between seiir forecast and case rate:', seiir_sq_err)\n",
    "print('SSE between kalman forecast and case rate:', kalman_sq_err)\n",
    "\n",
    "\n",
    "# plot findings, multiple plots ------------------\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "tick_start = K0\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=tick_start, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "fig1, ax11 = plt.subplots(1)\n",
    "plt.sca(ax11)\n",
    "width = 4\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Case Positive Rate', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.ylim(-2, 72)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "# plt.xlabel('Date')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "fig2, ax21 = plt.subplots(1)\n",
    "plt.sca(ax21)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Case Positive Rate', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.plot(predicted_case.index, predicted_case, label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "plt.ylim(-2, 72)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "# plt.xlabel('Date')\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "fig3, ax31 = plt.subplots(1)\n",
    "plt.sca(ax31)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Case Positive Rate', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.plot(predicted_case.index, predicted_case, label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "plt.ylim(-2, 72)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "# plt.xlabel('Date')\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "ax32 = ax31.twinx()\n",
    "plt.sca(ax32)\n",
    "plt.plot(prop_ma7.index, 100*prop_ma7, c='red', label='Facebook Symptom Rate',\n",
    "         linewidth=width)\n",
    "plt.ylim(-.065, 2.5)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor')\n",
    "\n",
    "plt.ylabel('Percentage of Positive Symptom Response')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
