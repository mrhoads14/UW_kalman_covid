{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs an extended Kalman filter using IHME SEIIR predictions along with measurement data of confirmed Covid-19 case counts (from New York Times data) and Facebook symptom data (loss of smell/taste, from Covid-19 Symptom Challenge) to generate updated 7-day predictions of case counts for counties in New York State.\n",
    "\n",
    "Developed by the University of Washington team of Les Atlas, Abraham Flaxman and Michael Rhoads.\n",
    "\n",
    "S - Susceptible\n",
    "E - Exposed\n",
    "I1 - Presymptomatic\n",
    "I2 - Symptomatic\n",
    "R - Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_sets\n",
    "import seiir_compartmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to support the Kalman filtering\n",
    "def get_predicts_prior(day, seiir):\n",
    "    x_hat = np.array([[seiir['S'].loc[day]],\n",
    "                      [seiir['E'].loc[day]],\n",
    "                      [seiir['I1'].loc[day]],\n",
    "                      [seiir['I2'].loc[day]],\n",
    "                      [seiir['R'].loc[day]]])\n",
    "\n",
    "    beta_k = seiir['beta'].loc[day]\n",
    "\n",
    "    return x_hat, beta_k\n",
    "\n",
    "\n",
    "def step_seiir(x_hat, constants, beta_k, days=7):\n",
    "    s_dict = {'S': x_hat[0, 0],\n",
    "              'E': x_hat[1, 0],\n",
    "              'I1': x_hat[2, 0],\n",
    "              'I2': x_hat[3, 0],\n",
    "              'R': x_hat[4, 0]}\n",
    "\n",
    "    s = pd.Series(s_dict)\n",
    "\n",
    "    for i in range(days):\n",
    "        infectious = s.loc['I1'] + s.loc['I2']\n",
    "        s = seiir_compartmental.compartmental_covid_step(s, s.sum(),\n",
    "                                                         infectious,\n",
    "                                                         constants['alpha'],\n",
    "                                                         beta_k,\n",
    "                                                         constants['gamma1'],\n",
    "                                                         constants['gamma2'],\n",
    "                                                         constants['sigma'],\n",
    "                                                         constants['theta'])\n",
    "    x_hat_future_prior = np.array([[s.loc['S']],\n",
    "                                   [s.loc['E']],\n",
    "                                   [s.loc['I1']],\n",
    "                                   [s.loc['I2']],\n",
    "                                   [s.loc['R']]])\n",
    "\n",
    "    return x_hat_future_prior\n",
    "\n",
    "\n",
    "def predict_step(x_hat_k1_prior, P, Q, beta_k, constants):\n",
    "    S = x_hat_k1_prior[0, 0]\n",
    "    E = x_hat_k1_prior[1, 0]\n",
    "    I1 = x_hat_k1_prior[2, 0]\n",
    "    I2 = x_hat_k1_prior[3, 0]\n",
    "    R = x_hat_k1_prior[4, 0]\n",
    "    N = S + E + I1 + I2 + R\n",
    "    alpha = constants['alpha']\n",
    "    sigma = constants['sigma']\n",
    "    gamma1 = constants['gamma1']\n",
    "    gamma2 = constants['gamma2']\n",
    "\n",
    "    part_f_S = np.array([[-beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_E = np.array([[0],\n",
    "                         [-sigma],\n",
    "                         [sigma],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_I1 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [-gamma1],\n",
    "                          [gamma1],\n",
    "                          [0]])\n",
    "\n",
    "    part_f_I2 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [0],\n",
    "                          [-gamma2],\n",
    "                          [gamma2]])\n",
    "\n",
    "    part_f_R = np.array([[0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    # 5x5\n",
    "    f_jacob = np.concatenate([part_f_S, part_f_E, part_f_I1, part_f_I2,\n",
    "                              part_f_R], axis=1)\n",
    "\n",
    "    # 5x5\n",
    "    # P_k1_prior = f_jacob * P * f_jacob^T + Q\n",
    "    P_k1_prior = np.matmul(np.matmul(f_jacob, P), np.transpose(f_jacob)) + Q\n",
    "    return P_k1_prior\n",
    "\n",
    "\n",
    "def update_step(x_hat, x_hat_k1, P_k1, Rn, rho1, rho2, z_k, measure):\n",
    "    # 5x5\n",
    "    ep = 10**-8\n",
    "    if measure is None:\n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, 0, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    else:\n",
    "                \n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, rho1, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    \n",
    "    \n",
    "    # Si = H * P_k1 * H^T + Rn\n",
    "    Si = np.matmul(np.matmul(H, P_k1), np.transpose(H)) + Rn\n",
    "\n",
    "    # K_new = P_k1 * H^T * Si^(-1)\n",
    "    K_new = np.matmul(np.matmul(P_k1, np.transpose(H)), np.linalg.inv(Si))\n",
    "    y_new = np.matmul(H, x_hat)\n",
    "\n",
    "    # 5x1\n",
    "    diff = z_k - y_new\n",
    "\n",
    "    x_hat_k1_post = x_hat_k1 + np.matmul(K_new, diff)\n",
    "\n",
    "    P_k1_post = P_k1 - np.matmul(np.matmul(K_new, Si), np.transpose(K_new))\n",
    "\n",
    "\n",
    "    return x_hat_k1_post, P_k1_post, diff, K_new[3, 3]\n",
    "\n",
    "\n",
    "def create_data_sets():\n",
    "    seiir_fl = pd.read_csv(r'data/seiir_projections/florida_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "\n",
    "    seiir_ny = pd.read_csv(r'data/seiir_projections/new_york_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "    \n",
    "    smell_data = data_sets.create_symptom_df()\n",
    "    \n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    \n",
    "    return seiir_fl, seiir_ny, smell_data, case_data\n",
    "\n",
    "\n",
    "def get_smell_data(fips, fb_data):\n",
    "\n",
    "    if fips == 'New York City':\n",
    "        nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "        fb_data_geo = fb_data.loc[(slice(None), '36081'), :].copy()\n",
    "        fb_data_geo = fb_data_geo.mean(level='date')\n",
    "\n",
    "        for borough in nyc_fips:\n",
    "            fb_data_geo += fb_data.loc[(slice(None), borough), :].copy().mean(level='date')\n",
    "\n",
    "    else:\n",
    "        fb_data_geo = fb_data.loc[(slice(None), fips), :].copy()\n",
    "\n",
    "        # collapse down to a single index column (date)\n",
    "        fb_data_geo.index = fb_data_geo.index.droplevel([0, 1])\n",
    "\n",
    "    return fb_data_geo\n",
    "    \n",
    "\n",
    "\n",
    "def calc_fb_ma7(fb_data):\n",
    "    \"\"\"\n",
    "    Returns a Pandas series\n",
    "    \"\"\"\n",
    "    # the fb_data is a DataFrame while the case_data is a Series\n",
    "    fb_ma7 = fb_data.rolling(window=7).mean()\n",
    "    fb_ma7 = fb_ma7.iloc[6:, :]\n",
    "    prop_ma7 = fb_ma7['num_stl'].div(fb_ma7['n'])\n",
    "\n",
    "    return prop_ma7, fb_ma7['n'].copy(), fb_ma7['num_stl'].copy()\n",
    "\n",
    "\n",
    "def calc_mse(prediction, actual):\n",
    "    \"\"\"\n",
    "    Inputs should be two Pandas Series of same length.\n",
    "    Outputs a float.\n",
    "    \"\"\"\n",
    "    err = prediction - actual\n",
    "    sum_sq_err = (err**2).sum()\n",
    "    mse = sum_sq_err / err.count()\n",
    "    return mse\n",
    "\n",
    "\n",
    "def create_hh_data():\n",
    "    # bring in new data\n",
    "    full_data = pd.read_csv(r'data/from_challenge/overall-county.csv', header=0, dtype={'fips': 'str', 'pct_hh_cli': 'float64'},\n",
    "                            parse_dates=[0])\n",
    "    time_start = full_data['date'].min()\n",
    "    time_end = full_data['date'].max()\n",
    "    full_data.set_index(['fips', 'date'], inplace=True)\n",
    "    full_data.sort_index(inplace=True)\n",
    "\n",
    "    # derive count of survey respondents with household members having covid symptoms\n",
    "    full_data['num_hh_cli'] = full_data['n'].mul(full_data['pct_hh_cli']/100.).round()\n",
    "    full_data['num_hh_cli'] = full_data['num_hh_cli'].astype('int64')\n",
    "\n",
    "    # group by county and date\n",
    "    data_of_interest = full_data[['n', 'num_hh_cli']].copy().groupby(level=(0, 1)).sum()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    # create full date range\n",
    "    date_rng = pd.date_range(time_start, time_end)\n",
    "    iterables = [data_of_interest.index.levels[0], date_rng]\n",
    "    new_index = pd.MultiIndex.from_product(iterables, names=['fips', 'date'])\n",
    "\n",
    "    data_of_interest = data_of_interest.reindex(index=new_index)\n",
    "    # this will have NaN values in the new index entries for which there was no\n",
    "    # previous data -- fill them upon extracting a particular county\n",
    "    \n",
    "    return data_of_interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ny_county_list():\n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    ny_counties = case_data[case_data['state'] == 'New York']['county'].unique()\n",
    "    return ny_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiir_fl, seiir_ny, smell_data, case_data = create_data_sets()\n",
    "\n",
    "hh_data = create_hh_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_county(the_state, county_name, seiir, smell_data, hh_data, case_data, measure='smell', K0=datetime.date(2020, 4, 18), delay=6):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        measure -- potential values are: 'smell', 'hh', or None\n",
    "    \"\"\"\n",
    "    # set constants\n",
    "    #K0 = datetime.date(2020, 4, 12)\n",
    "\n",
    "    if county_name == 'New York City':\n",
    "        the_county = county_name\n",
    "    else:\n",
    "        the_county = data_sets.get_fips(the_state, county_name)\n",
    "\n",
    "    constants = {\n",
    "        'alpha': 0.948786,\n",
    "        'gamma1': 0.500000,\n",
    "        'gamma2': 0.662215,\n",
    "        'sigma': 0.266635,\n",
    "        'theta': 6.000000\n",
    "        }\n",
    "\n",
    "    # set initial values for Kalman filter parameters\n",
    "    P_mult = 1\n",
    "    Q_mult = 1\n",
    "\n",
    "    # Rn is the R noise covariance matrix; it remains constant thru the stepping of the\n",
    "    # Kalman filter\n",
    "    Rn_mult = 5*10**-8\n",
    "\n",
    "    Rn_22 = 10000\n",
    "    Rn_32 = 1000\n",
    "\n",
    "    Rn_23 = 1000\n",
    "    Rn_33 = 100\n",
    "\n",
    "    Rn = Rn_mult * np.array([[0, 0, 0, 0, 0],\n",
    "                             [0, 0, 0, 0, 0],\n",
    "                             [0, 0, Rn_22, Rn_23, 0],\n",
    "                             [0, 0, Rn_32, Rn_33, 0],\n",
    "                             [0, 0, 0, 0, 0]])\n",
    "\n",
    "    Q = Q_mult * np.eye(5)\n",
    "    P = P_mult * np.eye(5)\n",
    "    \n",
    "    if the_county == 'New York City':\n",
    "        county_pop = 0\n",
    "        for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "            this_count, state_pop = data_sets.get_pops(each)\n",
    "            county_pop += this_count\n",
    "    else:\n",
    "        county_pop, state_pop = data_sets.get_pops(the_county)\n",
    "\n",
    "    b = county_pop / state_pop\n",
    "\n",
    "    # generate data\n",
    "    case_data_geo = case_data.loc[the_county]['case_rate'].copy()\n",
    "    smell_data_geo = get_smell_data(the_county, smell_data)\n",
    "    \n",
    "\n",
    "    if measure == 'hh':\n",
    "        idx = pd.IndexSlice\n",
    "        \n",
    "        if the_county == 'New York City':\n",
    "            nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "            hh_cli = hh_data.loc[idx['36081', :], :].loc['36081'].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "            for borough in nyc_fips:\n",
    "                bor_hh_cli = hh_data.loc[idx[borough, :], :].loc[borough].copy()\n",
    "                bor_hh_cli.fillna(method='pad', inplace=True)\n",
    "                hh_cli += bor_hh_cli\n",
    "\n",
    "        else:\n",
    "            hh_cli = hh_data.loc[idx[the_county, :], :].loc[the_county].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "        # calculate moving averages on the fb and case data\n",
    "        hh_cli_ma7 = hh_cli.rolling(window=7).mean()\n",
    "        hh_cli_ma7 = hh_cli_ma7.iloc[6:, :]\n",
    "        num_survey_ma7 = hh_cli_ma7['num_hh_cli']\n",
    "        prop_cli_ma7 = num_survey_ma7.div(hh_cli_ma7['n'])\n",
    "        \n",
    "    elif measure == 'smell':\n",
    "        prop_ma7, n_ma7, num_survey_ma7 = calc_fb_ma7(smell_data_geo)\n",
    "        \n",
    "    else:\n",
    "        num_survey_ma7 = None\n",
    "\n",
    "\n",
    "    case_ma7 = case_data_geo.rolling(window=7).mean()\n",
    "    case_ma7_all = case_ma7.iloc[6:]\n",
    "    \n",
    "\n",
    "    # get starting compartment values for the state level\n",
    "    x_hat_state_k0, beta_k0 = get_predicts_prior(K0, seiir)\n",
    "\n",
    "    # convert to the county level\n",
    "    x_hat_k0 = b * x_hat_state_k0\n",
    "\n",
    "    I2_county = x_hat_k0[3, 0]\n",
    "\n",
    "\n",
    "    rho1 = 0.0001\n",
    "    rho2 = case_ma7_all.loc['2020-04-12'] / I2_county\n",
    "\n",
    "\n",
    "    # create empty dictionaries to hold the estimated values\n",
    "    case_est = {}\n",
    "    seiir_pred = {}\n",
    "\n",
    "    diff_rat = {}\n",
    "\n",
    "    K_val_dict = {}\n",
    "\n",
    "\n",
    "    # Original data run ----------------\n",
    "    start = K0\n",
    "    d = start\n",
    "\n",
    "    while d <= datetime.date(2020, 10, 23):    \n",
    "\n",
    "    # each cycle of the while loop executes a step\n",
    "\n",
    "        # get state level compartments\n",
    "        x_hat_state_k, beta_k = get_predicts_prior(d, seiir)\n",
    "\n",
    "        # step the state level compartments 7 days forward\n",
    "        x_hat_state_k1 = step_seiir(x_hat_state_k, constants, beta_k)\n",
    "\n",
    "        # convert the state level compartments to county level values\n",
    "        x_hat_k = b * x_hat_state_k\n",
    "        x_hat_k1 = b * x_hat_state_k1\n",
    "\n",
    "        indexDate = d + datetime.timedelta(days=7)\n",
    "        # store seiir prediction before it's modified by Kalman filter\n",
    "        seiir_pred[indexDate] = x_hat_k1[3, 0]\n",
    "\n",
    "        # get measurements for current day\n",
    "        if measure == 'smell':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_ma7.loc[d - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[d]],\n",
    "                            [0]])    \n",
    "\n",
    "        elif measure == 'hh':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_cli_ma7.loc[d - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[d]],\n",
    "                            [0]])\n",
    "            \n",
    "        else:\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [0],\n",
    "                            [case_ma7_all.loc[d]],\n",
    "                            [0]])\n",
    "\n",
    "        # predict step using the stepped fwd SEIIR compartment values \n",
    "        P = predict_step(x_hat_k1, P, Q, beta_k, constants)\n",
    "\n",
    "        # update step\n",
    "        x_hat_post, P_post, the_diff, K_val = update_step(x_hat_k, x_hat_k1, P, Rn,\n",
    "                                         rho1, rho2, z_k, measure)\n",
    "\n",
    "\n",
    "        # store estimated values for proportion and case rate\n",
    "        K_val_dict[indexDate] = K_val\n",
    "        case_est[indexDate] = rho2 * x_hat_post[3, 0]\n",
    "\n",
    "\n",
    "        diff_rat[indexDate] = the_diff[2, 0] / the_diff[3, 0]\n",
    "\n",
    "        # update the P and d\n",
    "        P = P_post\n",
    "        d += datetime.timedelta(days=1)\n",
    "\n",
    "    # create pandas series of the estimated case rate\n",
    "    predicted_case = pd.Series(case_est)\n",
    "    predicted_seiir_prior = pd.Series(seiir_pred)\n",
    "    K_val_series = pd.Series(K_val_dict)\n",
    "    \n",
    "    return predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_val_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', 'Westchester', seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=datetime.date(2020, 4, 18), delay=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting New York City\n",
      "Complete with New York City\n"
     ]
    }
   ],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "\n",
    "ny_counties = create_ny_county_list()\n",
    "df_index = []\n",
    "err_data = []\n",
    "\n",
    "predictions_case_only = pd.DataFrame()\n",
    "predictions_smell_0delay = pd.DataFrame()\n",
    "predictions_smell_6delay = pd.DataFrame()\n",
    "predictions_hh_0delay = pd.DataFrame()\n",
    "predictions_hh_6delay = pd.DataFrame()\n",
    "\n",
    "left = K0 + datetime.timedelta(days=7)\n",
    "right = datetime.date(2020, 10, 23)\n",
    "\n",
    "for each in ny_counties:\n",
    "    if each == 'New York City':\n",
    "        fips = 'New York City'\n",
    "    else:\n",
    "        fips = data_sets.get_fips('NY', each)\n",
    "        if (fips not in hh_data.index.levels[0]) or (fips not in smell_data.index.levels[1]):\n",
    "            continue\n",
    "    \n",
    "    print('Starting', fips)\n",
    "    \n",
    "    county_data = {}\n",
    "    \n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure=None, K0=K0, delay=0)\n",
    "    county_data['mse_confirmed-only'] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    predictions_case_only[each] = predicted_case\n",
    "    \n",
    "\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=0)\n",
    "    county_data['mse_smell-0delay'] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    predictions_smell_0delay[each] = predicted_case\n",
    "    \n",
    "\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=6)\n",
    "    county_data['mse_smell-6delay'] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    predictions_smell_6delay[each] = predicted_case\n",
    "    \n",
    "\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=0)\n",
    "    county_data['mse_hh-0delay'] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    predictions_hh_0delay[each] = predicted_case\n",
    "    \n",
    "\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=6)\n",
    "    county_data['mse_hh-6delay'] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    predictions_hh_6delay[each] = predicted_case\n",
    "    \n",
    "    df_index.append(fips)\n",
    "    err_data.append(county_data)\n",
    "    print('Complete with', fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mse_confirmed-only': 30503.884158190707,\n",
       "  'mse_smell-0delay': 30918.89834954391,\n",
       "  'mse_smell-6delay': 31120.081178154087,\n",
       "  'mse_hh-0delay': 30582.06780755661,\n",
       "  'mse_hh-6delay': 31113.70747269597}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['36005', '36061', '36047', '36085', '36081']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '36005' not in smell_data.index.levels[1]:\n",
    "    print('not in there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('36123' not in hh_data.index.levels[0]) or ('36123' not in smell_data.index.levels[1]):\n",
    "    print('not in there!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York City']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New York City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-25</th>\n",
       "      <td>3294.172813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-26</th>\n",
       "      <td>3108.061050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>2972.785847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>2822.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>2205.671129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>645.237743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>619.298111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>674.681808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>678.659192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>666.153813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            New York City\n",
       "2020-04-25    3294.172813\n",
       "2020-04-26    3108.061050\n",
       "2020-04-27    2972.785847\n",
       "2020-04-28    2822.001753\n",
       "2020-04-29    2205.671129\n",
       "...                   ...\n",
       "2020-10-26     645.237743\n",
       "2020-10-27     619.298111\n",
       "2020-10-28     674.681808\n",
       "2020-10-29     678.659192\n",
       "2020-10-30     666.153813\n",
       "\n",
       "[189 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_case_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in ny_counties:\n",
    "    fips = data_sets.get_fips('NY', each)\n",
    "    print(each, fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_case_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute squared error for the overlapping time period -------------------------\n",
    "d = datetime.date(2020, 10, 23)\n",
    "start = datetime.date(2020, 4, 18)\n",
    "\n",
    "left = predicted_seiir_prior.index[0]\n",
    "right = d\n",
    "\n",
    "seiir_err = case_ma7_all.loc[left:right] - predicted_seiir_prior[left:right]\n",
    "seiir_sum_sq_err = (seiir_err**2).sum()\n",
    "seiir_mse = seiir_sum_sq_err / seiir_err.count()\n",
    "\n",
    "kalman_err = predicted_case.loc[left:right] - case_ma7_all.loc[left:right]\n",
    "kalman_sum_sq_err = (kalman_err**2).sum()\n",
    "kalman_mse = kalman_sum_sq_err / kalman_err.count()\n",
    "\n",
    "\n",
    "print('SSE between seiir forecast and case rate:', seiir_sum_sq_err)\n",
    "print('MSE between seiir forecast and measured case rate:', seiir_mse)\n",
    "print()\n",
    "print('SSE between kalman forecast and case rate:', kalman_sum_sq_err)\n",
    "print('MSE between kalman forecast and measured case rate:', kalman_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['test'] = predicted_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame()\n",
    "output_df[the_county] = predicted_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(r'output/predicted_case_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All plotting code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim_left = None\n",
    "xlim_right = None\n",
    "\n",
    "leftylim_low = None\n",
    "leftylim_high = None\n",
    "\n",
    "rightylim_low = None\n",
    "rightylim_high = None\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot findings -- multiple plots\n",
    "\n",
    "# Plotting constants and variables ----------------\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "purple = '#33016F'\n",
    "gold = '#9E7A27'\n",
    "gray = '#797979'\n",
    "width = 4\n",
    "%matplotlib qt\n",
    "\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=start, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple plots -----------\n",
    "fig1, ax11 = plt.subplots(1)\n",
    "plt.sca(ax11)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "\n",
    "fig2, ax21 = plt.subplots(1)\n",
    "plt.sca(ax21)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig3, ax31 = plt.subplots(1)\n",
    "plt.sca(ax31)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "\n",
    "ax32 = ax31.twinx()\n",
    "plt.sca(ax32)\n",
    "plt.plot(num_stl_ma7.loc[start:d].index, num_stl_ma7.loc[start:d], c='red', label='FB Positive Symptoms, Smell/Taste Loss',\n",
    "         linewidth=width)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Positive Symptom Response per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\n",
    "\n",
    "plt.sca(ax31)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax41 = plt.subplots(1)\n",
    "plt.sca(ax41)\n",
    "plt.plot(case_ma7_all.loc[start:d].index, case_ma7_all.loc[start:d], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "#naieve estimate\n",
    "naive_start = start + datetime.timedelta(days=7)\n",
    "naive_d = d + datetime.timedelta(days=7)\n",
    "plt.plot(case_ma7_all.loc[naive_start:naive_d].index, case_ma7_all.loc[start:d], label='Naive guess', c='orange')\n",
    "\n",
    "ax42 = ax41.twinx()\n",
    "plt.sca(ax42)\n",
    "plt.plot(num_survey_ma7.loc[start:d].index, num_survey_ma7.loc[start:d], c='red', label='FB Positive Symptoms, Smell/Taste Loss',\n",
    "         linewidth=width)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Positive Household Symptom Response per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\n",
    "\n",
    "plt.sca(ax41)\n",
    "plt.plot(predicted_case.loc[start:].index, predicted_case.loc[start:], label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_ma7_all.loc[d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## special end date\n",
    "\n",
    "# plot findings -- multiple plots\n",
    "\n",
    "# Plotting constants and variables ----------------\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "purple = '#33016F'\n",
    "gold = '#9E7A27'\n",
    "gray = '#797979'\n",
    "width = 4\n",
    "%matplotlib qt\n",
    "\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=start, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "\n",
    "fig1, ax11 = plt.subplots(1)\n",
    "plt.sca(ax11)\n",
    "plt.plot(case_ma7_all.loc[start:tick_end].index, case_ma7_all.loc[start:tick_end], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "\n",
    "fig2, ax21 = plt.subplots(1)\n",
    "plt.sca(ax21)\n",
    "plt.plot(case_ma7_all.loc[start:tick_end].index, case_ma7_all.loc[start:tick_end], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig3, ax31 = plt.subplots(1)\n",
    "plt.sca(ax31)\n",
    "plt.plot(case_ma7_all.loc[start:tick_end].index, case_ma7_all.loc[start:tick_end], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "\n",
    "ax32 = ax31.twinx()\n",
    "plt.sca(ax32)\n",
    "plt.plot(num_stl_ma7.loc[start:tick_end].index, num_stl_ma7.loc[start:tick_end], c='red', label='FB Positive Symptoms, Smell/Taste Loss',\n",
    "         linewidth=width)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Positive Symptom Response per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\n",
    "\n",
    "plt.sca(ax31)\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "\n",
    "\n",
    "fig4, ax41 = plt.subplots(1)\n",
    "plt.sca(ax41)\n",
    "plt.plot(case_ma7_all.loc[start:tick_end].index, case_ma7_all.loc[start:tick_end], label='Confirmed Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "\n",
    "ax42 = ax41.twinx()\n",
    "plt.sca(ax42)\n",
    "plt.plot(num_stl_ma7.loc[start:tick_end].index, num_stl_ma7.loc[start:tick_end], c='red', label='FB Positive Symptoms, Smell/Taste Loss',\n",
    "         linewidth=width)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Positive Symptom Response per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\n",
    "\n",
    "plt.sca(ax41)\n",
    "plt.plot(predicted_case.loc[start:].index, predicted_case.loc[start:], label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC plot settings\n",
    "\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -700\n",
    "leftylim_high = 12000\n",
    "\n",
    "rightylim_low = -5\n",
    "rightylim_high = 85\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nassau plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -40\n",
    "leftylim_high = 1650\n",
    "\n",
    "rightylim_low = -.3\n",
    "rightylim_high = 12\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Westchester plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -28\n",
    "leftylim_high = 1000\n",
    "\n",
    "rightylim_low = -.2\n",
    "rightylim_high = 7\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albany plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -3\n",
    "leftylim_high = 75\n",
    "\n",
    "rightylim_low = -.125\n",
    "rightylim_high = 3.1\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erie plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 10, 13)\n",
    "\n",
    "leftylim_low = -10\n",
    "leftylim_high = 250\n",
    "\n",
    "rightylim_low = -.5\n",
    "rightylim_high = 12.5\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
