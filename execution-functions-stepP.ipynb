{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs an extended Kalman filter using IHME SEIIR predictions along with measurement data of confirmed Covid-19 case counts (from New York Times data) and CMU/Facebook symptom data (from Covid-19 Symptom Challenge) to generate updated 7-day predictions of case counts for counties in New York State and Florida.\n",
    "\n",
    "Developed by the University of Washington team of Les Atlas, Abraham Flaxman and Michael Rhoads.\n",
    "\n",
    "S - Susceptible\n",
    "E - Exposed\n",
    "I1 - Presymptomatic\n",
    "I2 - Symptomatic\n",
    "R - Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_sets\n",
    "import seiir_compartmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to support the Kalman filtering\n",
    "def get_predicts_prior(day, seiir):\n",
    "    x_hat = np.array([[seiir['S'].loc[day]],\n",
    "                      [seiir['E'].loc[day]],\n",
    "                      [seiir['I1'].loc[day]],\n",
    "                      [seiir['I2'].loc[day]],\n",
    "                      [seiir['R'].loc[day]]])\n",
    "\n",
    "    beta_k = seiir['beta'].loc[day]\n",
    "\n",
    "    return x_hat, beta_k\n",
    "\n",
    "\n",
    "def step_seiir(x_hat, constants, beta_k, days=7):\n",
    "    s_dict = {'S': x_hat[0, 0],\n",
    "              'E': x_hat[1, 0],\n",
    "              'I1': x_hat[2, 0],\n",
    "              'I2': x_hat[3, 0],\n",
    "              'R': x_hat[4, 0]}\n",
    "\n",
    "    s = pd.Series(s_dict)\n",
    "\n",
    "    for i in range(days):\n",
    "        infectious = s.loc['I1'] + s.loc['I2']\n",
    "        s = seiir_compartmental.compartmental_covid_step(s, s.sum(),\n",
    "                                                         infectious,\n",
    "                                                         constants['alpha'],\n",
    "                                                         beta_k,\n",
    "                                                         constants['gamma1'],\n",
    "                                                         constants['gamma2'],\n",
    "                                                         constants['sigma'],\n",
    "                                                         constants['theta'])\n",
    "    x_hat_future_prior = np.array([[s.loc['S']],\n",
    "                                   [s.loc['E']],\n",
    "                                   [s.loc['I1']],\n",
    "                                   [s.loc['I2']],\n",
    "                                   [s.loc['R']]])\n",
    "\n",
    "    return x_hat_future_prior\n",
    "\n",
    "\n",
    "def predict_step(x_hat_k1_prior, P, Q, beta_k, constants):\n",
    "    S = x_hat_k1_prior[0, 0]\n",
    "    E = x_hat_k1_prior[1, 0]\n",
    "    I1 = x_hat_k1_prior[2, 0]\n",
    "    I2 = x_hat_k1_prior[3, 0]\n",
    "    R = x_hat_k1_prior[4, 0]\n",
    "    N = S + E + I1 + I2 + R\n",
    "    alpha = constants['alpha']\n",
    "    sigma = constants['sigma']\n",
    "    gamma1 = constants['gamma1']\n",
    "    gamma2 = constants['gamma2']\n",
    "\n",
    "    part_f_S = np.array([[-beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_E = np.array([[0],\n",
    "                         [-sigma],\n",
    "                         [sigma],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_I1 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [-gamma1],\n",
    "                          [gamma1],\n",
    "                          [0]])\n",
    "\n",
    "    part_f_I2 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [0],\n",
    "                          [-gamma2],\n",
    "                          [gamma2]])\n",
    "    \n",
    "    part_f_R = np.array([[0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    # 5x5\n",
    "    f_jacob = np.concatenate([part_f_S, part_f_E, part_f_I1, part_f_I2,\n",
    "                              part_f_R], axis=1)\n",
    "\n",
    "\n",
    "    # 5x5\n",
    "    # P_prior = f_jacob * P * f_jacob^T + Q\n",
    "    P_prior = np.matmul(np.matmul(f_jacob, P), f_jacob.T) + Q\n",
    "    \n",
    "    return P_prior\n",
    "\n",
    "\n",
    "def update_step(x_hat, x_hat_k1, P_prior, Rn, rho1, rho2, z_k, measure):\n",
    "    # 5x5\n",
    "    ep = 10**-8\n",
    "    \n",
    "    # if there is no survey measurement used, then rho1 is not needed\n",
    "    if measure is None:\n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, 0, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    else:\n",
    "                \n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, rho1, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    \n",
    "    \n",
    "    # Si = H * P_prior * H^T + Rn\n",
    "    Si = np.matmul(np.matmul(H, P_prior), H.T) + Rn\n",
    "\n",
    "    # K = P_prior * H.T (H * P_prior * H.T + R)^-1\n",
    "    # K_new = P_prior * H^T * Si^(-1)\n",
    "    K_new = np.matmul(np.matmul(P_prior, H.T), np.linalg.inv(Si))\n",
    "    \n",
    "    y_new = np.matmul(H, x_hat)\n",
    "\n",
    "    # 5x1\n",
    "    diff = z_k - y_new\n",
    "\n",
    "    x_hat_k1_post = x_hat_k1 + np.matmul(K_new, diff)\n",
    "\n",
    "    P_post = P_prior - np.matmul(np.matmul(K_new, Si), K_new.T)\n",
    "\n",
    "\n",
    "    return x_hat_k1_post, P_post, diff, K_new[3, 3]\n",
    "\n",
    "\n",
    "def create_data_sets():\n",
    "    seiir_fl = pd.read_csv(r'data/seiir_projections/florida_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "\n",
    "    seiir_ny = pd.read_csv(r'data/seiir_projections/new_york_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "    \n",
    "    smell_data = data_sets.create_symptom_df()\n",
    "    \n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    \n",
    "    return seiir_fl, seiir_ny, smell_data, case_data\n",
    "\n",
    "\n",
    "def get_smell_data(fips, fb_data):\n",
    "\n",
    "    if fips == 'New York City':\n",
    "        nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "        fb_data_geo = fb_data.loc[(slice(None), '36081'), :].copy()\n",
    "        fb_data_geo = fb_data_geo.mean(level='date')\n",
    "\n",
    "        for borough in nyc_fips:\n",
    "            fb_data_geo += fb_data.loc[(slice(None), borough), :].copy().mean(level='date')\n",
    "\n",
    "    else:\n",
    "        fb_data_geo = fb_data.loc[(slice(None), fips), :].copy()\n",
    "\n",
    "        # collapse down to a single index column (date)\n",
    "        fb_data_geo.index = fb_data_geo.index.droplevel([0, 1])\n",
    "\n",
    "    return fb_data_geo\n",
    "    \n",
    "\n",
    "\n",
    "def calc_fb_ma7(fb_data):\n",
    "    \"\"\"\n",
    "    Returns a Pandas series\n",
    "    \"\"\"\n",
    "    # the fb_data is a DataFrame while the case_data is a Series\n",
    "    fb_ma7 = fb_data.rolling(window=7).mean()\n",
    "    fb_ma7 = fb_ma7.iloc[6:, :]\n",
    "    prop_ma7 = fb_ma7['num_stl'].div(fb_ma7['n'])\n",
    "\n",
    "    return prop_ma7, fb_ma7['n'].copy(), fb_ma7['num_stl'].copy()\n",
    "\n",
    "\n",
    "def calc_mse(prediction, actual):\n",
    "    \"\"\"\n",
    "    Inputs should be two Pandas Series of same length.\n",
    "    Outputs a float.\n",
    "    \"\"\"\n",
    "    err = prediction - actual\n",
    "    sum_sq_err = (err**2).sum()\n",
    "    mse = sum_sq_err / err.count()\n",
    "    return mse\n",
    "\n",
    "\n",
    "def create_hh_data():\n",
    "    # bring in household covid symptom data\n",
    "    full_data = pd.read_csv(r'data/fb_hh_cli.csv', header=0, dtype={'fips': 'str',\n",
    "                                                                    'n': 'int64',\n",
    "                                                                    'hh_cli': 'float64'},\n",
    "                                                            parse_dates=[2])\n",
    "    full_data['fips'] = full_data['fips'].str.replace('(^[0-9]{4}\\.0)', '0\\g<1>')\n",
    "    full_data['fips'] = full_data['fips'].str.extract('(^[0-9]{5})')\n",
    "    time_start = full_data['date'].min()\n",
    "    time_end = full_data['date'].max()\n",
    "    full_data.set_index(['fips', 'date'], inplace=True)\n",
    "    full_data.sort_index(inplace=True)\n",
    "\n",
    "    # derive count of survey respondents with household members having covid symptoms\n",
    "    full_data['num_hh_cli'] = full_data['n'].mul(full_data['hh_cli']).round()\n",
    "    full_data['num_hh_cli'] = full_data['num_hh_cli'].astype('int64')\n",
    "\n",
    "    # group by county and date\n",
    "    data_of_interest = full_data[['n', 'num_hh_cli']].copy().groupby(level=(0, 1)).sum()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    # create full date range\n",
    "    date_rng = pd.date_range(time_start, time_end)\n",
    "    iterables = [data_of_interest.index.levels[0], date_rng]\n",
    "    new_index = pd.MultiIndex.from_product(iterables, names=['fips', 'date'])\n",
    "\n",
    "    data_of_interest = data_of_interest.reindex(index=new_index)\n",
    "    # this will have NaN values in the new index entries for which there was no\n",
    "    # previous data -- fill them upon extracting a particular county\n",
    "    \n",
    "    return data_of_interest\n",
    "\n",
    "\n",
    "def create_county_lists():\n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    ny_counties = case_data[case_data['state'] == 'New York']['county'].unique()\n",
    "    fl_counties = case_data[case_data['state'] == 'Florida']['county'].unique()\n",
    "    return ny_counties, fl_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data sets\n",
    "\n",
    "seiir_fl, seiir_ny, smell_data, case_data = create_data_sets()\n",
    "hh_data = create_hh_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-12-31 00:00:00')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seiir_ny.index[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_county(the_state, county_name, seiir, smell_data, hh_data, case_data, measure='smell', K0=datetime.date(2020, 4, 18), delay=6):\n",
    "    \"\"\"\n",
    "    The main function that calculates the forecast for a given county over the entire time range\n",
    "    Arguments:\n",
    "        measure -- potential values are: 'smell', 'hh', or None\n",
    "    \"\"\"\n",
    "    # set constants\n",
    "    #K0 = datetime.date(2020, 4, 12)\n",
    "\n",
    "    if county_name == 'New York City':\n",
    "        the_county = county_name\n",
    "    else:\n",
    "        the_county = data_sets.get_fips(the_state, county_name)\n",
    "\n",
    "    constants = {\n",
    "        'alpha': 0.948786,\n",
    "        'gamma1': 0.500000,\n",
    "        'gamma2': 0.662215,\n",
    "        'sigma': 0.266635,\n",
    "        'theta': 6.000000\n",
    "        }\n",
    "\n",
    "    # set initial values for Kalman filter parameters\n",
    "    P_mult = 1\n",
    "    Q_mult = 1\n",
    "\n",
    "    # Rn is the R noise covariance matrix; it remains constant thru the stepping of the\n",
    "    # Kalman filter\n",
    "    Rn_mult = 5*10**-8\n",
    "\n",
    "    Rn_22 = 10000\n",
    "    Rn_32 = 1000\n",
    "\n",
    "    Rn_23 = 1000\n",
    "    Rn_33 = 100\n",
    "\n",
    "    Rn = Rn_mult * np.array([[0, 0, 0, 0, 0],\n",
    "                             [0, 0, 0, 0, 0],\n",
    "                             [0, 0, Rn_22, Rn_23, 0],\n",
    "                             [0, 0, Rn_32, Rn_33, 0],\n",
    "                             [0, 0, 0, 0, 0]])\n",
    "\n",
    "    Q = Q_mult * np.eye(5)\n",
    "    P = P_mult * np.eye(5)\n",
    "    \n",
    "    if the_county == 'New York City':\n",
    "        county_pop = 0\n",
    "        for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "            this_count, state_pop = data_sets.get_pops(each)\n",
    "            county_pop += this_count\n",
    "    else:\n",
    "        county_pop, state_pop = data_sets.get_pops(the_county)\n",
    "\n",
    "    b = county_pop / state_pop\n",
    "\n",
    "    # generate data\n",
    "    case_data_geo = case_data.loc[the_county]['case_rate'].copy()\n",
    "    smell_data_geo = get_smell_data(the_county, smell_data)\n",
    "    \n",
    "\n",
    "    if measure == 'hh':\n",
    "        idx = pd.IndexSlice\n",
    "        \n",
    "        if the_county == 'New York City':\n",
    "            nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "            hh_cli = hh_data.loc[idx['36081', :], :].loc['36081'].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "            for borough in nyc_fips:\n",
    "                bor_hh_cli = hh_data.loc[idx[borough, :], :].loc[borough].copy()\n",
    "                bor_hh_cli.fillna(method='pad', inplace=True)\n",
    "                hh_cli += bor_hh_cli\n",
    "\n",
    "        else:\n",
    "            hh_cli = hh_data.loc[idx[the_county, :], :].loc[the_county].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "        # calculate moving averages on the fb and case data\n",
    "        hh_cli_ma7 = hh_cli.rolling(window=7).mean()\n",
    "        hh_cli_ma7 = hh_cli_ma7.iloc[6:, :]\n",
    "        num_survey_ma7 = hh_cli_ma7['num_hh_cli']\n",
    "        prop_cli_ma7 = num_survey_ma7.div(hh_cli_ma7['n'])\n",
    "        \n",
    "    elif measure == 'smell':\n",
    "        prop_ma7, n_ma7, num_survey_ma7 = calc_fb_ma7(smell_data_geo)\n",
    "        \n",
    "    else:\n",
    "        num_survey_ma7 = None\n",
    "\n",
    "\n",
    "    case_ma7 = case_data_geo.rolling(window=7).mean()\n",
    "    case_ma7_all = case_ma7.iloc[6:]\n",
    "    \n",
    "\n",
    "    # get starting compartment values for the state level\n",
    "    x_hat_state_k0, beta_k0 = get_predicts_prior(K0, seiir)\n",
    "\n",
    "    # convert to the county level\n",
    "    x_hat_k0 = b * x_hat_state_k0\n",
    "\n",
    "    I2_county = x_hat_k0[3, 0]\n",
    "\n",
    "\n",
    "    rho1 = .05\n",
    "    rho2 = case_ma7_all.loc['2020-04-12'] / I2_county\n",
    "\n",
    "\n",
    "    # create empty dictionaries to hold the estimated values\n",
    "    case_est = {}\n",
    "    seiir_pred = {}\n",
    "\n",
    "    diff_rat = {}\n",
    "\n",
    "    K_val_dict = {}\n",
    "\n",
    "\n",
    "    # Original data run ----------------\n",
    "    start = K0\n",
    "    k = start\n",
    "\n",
    "    while k <= datetime.date(2020, 12, 8):\n",
    "        # previous constraint was 2020-10-23\n",
    "\n",
    "    # each cycle of the while loop executes a step\n",
    "\n",
    "        # get state level compartments\n",
    "        x_hat_state_k, beta_k = get_predicts_prior(k, seiir)\n",
    "\n",
    "        # step the state level compartments 1 day forward\n",
    "        x_hat_state_k1 = step_seiir(x_hat_state_k, constants, beta_k, days=1)\n",
    "        P = predict_step(x_hat_state_k, P, Q, beta_k, constants)\n",
    "        \n",
    "        # then 6 more\n",
    "        P_est = P.copy()\n",
    "        for i in range(6):\n",
    "            x_hat_est = step_seiir(x_hat_state_k1, constants, beta_k, days=1)\n",
    "            P_est = predict_step(x_hat_state_k1, P_est, Q, beta_k, constants)\n",
    "            x_hat_state_k1 = x_hat_est.copy()\n",
    "\n",
    "        # convert the state level compartments to county level values\n",
    "        x_hat_k = b * x_hat_state_k\n",
    "        x_hat_k1 = b * x_hat_state_k1\n",
    "\n",
    "        \n",
    "        indexDate = k + datetime.timedelta(days=7)\n",
    "        # store seiir prediction before it's modified by Kalman filter\n",
    "        # multiply by rho2 to get values equivalent to confirmed case count\n",
    "        seiir_pred[indexDate] = rho2 * x_hat_k1[3, 0]\n",
    "\n",
    "        # get measurements for current day\n",
    "        if measure == 'smell':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_ma7.loc[k - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])    \n",
    "\n",
    "        elif measure == 'hh':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_cli_ma7.loc[k - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])\n",
    "            \n",
    "        else:\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [0],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])\n",
    "\n",
    "        # predict step using the stepped fwd SEIIR compartment values \n",
    "        #P = predict_step(x_hat_k1, P, Q, beta_k, constants)\n",
    "\n",
    "        # update step\n",
    "        x_hat_post, P_post, the_diff, K_val = update_step(x_hat_k, x_hat_k1, P_est, Rn,\n",
    "                                         rho1, rho2, z_k, measure)\n",
    "\n",
    "\n",
    "        # store estimated values for proportion and case rate\n",
    "        K_val_dict[indexDate] = K_val\n",
    "        case_est[indexDate] = rho2 * x_hat_post[3, 0]\n",
    "\n",
    "\n",
    "        diff_rat[indexDate] = the_diff[2, 0] / the_diff[3, 0]\n",
    "\n",
    "        # update the P and k\n",
    "        # comment out the P update because it has already been stepped once\n",
    "        #P = P_post\n",
    "        k += datetime.timedelta(days=1)\n",
    "\n",
    "    # create pandas series of the estimated case rate\n",
    "    predicted_case = pd.Series(case_est)\n",
    "    predicted_seiir_prior = pd.Series(seiir_pred)\n",
    "    K_val_series = pd.Series(K_val_dict)\n",
    "    \n",
    "    return predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_val_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single county run\n",
    "predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', 'Nassau', seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=datetime.date(2020, 4, 18), delay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "\n",
    "ny_counties, fl_counties = create_county_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alachua', 'Baker', 'Bay', 'Bradford', 'Brevard', 'Broward',\n",
       "       'Calhoun', 'Charlotte', 'Citrus', 'Clay', 'Collier', 'Columbia',\n",
       "       'DeSoto', 'Dixie', 'Duval', 'Escambia', 'Flagler', 'Franklin',\n",
       "       'Gadsden', 'Gilchrist', 'Glades', 'Gulf', 'Hamilton', 'Hardee',\n",
       "       'Hendry', 'Hernando', 'Highlands', 'Hillsborough', 'Holmes',\n",
       "       'Indian River', 'Jackson', 'Jefferson', 'Lafayette', 'Lake', 'Lee',\n",
       "       'Leon', 'Levy', 'Liberty', 'Madison', 'Manatee', 'Marion',\n",
       "       'Martin', 'Miami-Dade', 'Monroe', 'Nassau', 'Okaloosa',\n",
       "       'Okeechobee', 'Orange', 'Osceola', 'Palm Beach', 'Pasco',\n",
       "       'Pinellas', 'Polk', 'Putnam', 'St. Johns', 'St. Lucie',\n",
       "       'Santa Rosa', 'Sarasota', 'Seminole', 'Sumter', 'Suwannee',\n",
       "       'Taylor', 'Union', 'Volusia', 'Wakulla', 'Walton', 'Washington'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = predicted_case.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast NY State counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_range = pd.date_range(start=left, end=right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shifted_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 36001\n",
      "Complete with 36001\n",
      "Starting 36003\n",
      "Complete with 36003\n",
      "Starting 36007\n",
      "Complete with 36007\n",
      "Starting 36009\n",
      "Complete with 36009\n",
      "Starting 36011\n",
      "Complete with 36011\n",
      "Starting 36013\n",
      "Complete with 36013\n",
      "Starting 36015\n",
      "Complete with 36015\n",
      "Starting 36017\n",
      "Complete with 36017\n",
      "Starting 36019\n",
      "Complete with 36019\n",
      "Starting 36021\n",
      "Complete with 36021\n",
      "Starting 36023\n",
      "Complete with 36023\n",
      "Starting 36025\n",
      "Complete with 36025\n",
      "Starting 36027\n",
      "Complete with 36027\n",
      "Starting 36029\n",
      "Complete with 36029\n",
      "Starting 36031\n",
      "Complete with 36031\n",
      "Starting 36033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhoa\\miniconda3\\envs\\covid_DOA\\lib\\site-packages\\ipykernel_launcher.py:185: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete with 36033\n",
      "Starting 36035\n",
      "Complete with 36035\n",
      "Starting 36037\n",
      "Complete with 36037\n",
      "Starting 36039\n",
      "Complete with 36039\n",
      "Starting 36041\n",
      "Complete with 36041\n",
      "Starting 36043\n",
      "Complete with 36043\n",
      "Starting 36045\n",
      "Complete with 36045\n",
      "Starting 36049\n",
      "Complete with 36049\n",
      "Starting 36051\n",
      "Complete with 36051\n",
      "Starting 36053\n",
      "Complete with 36053\n",
      "Starting 36055\n",
      "Complete with 36055\n",
      "Starting 36057\n",
      "Complete with 36057\n",
      "Starting 36059\n",
      "Complete with 36059\n",
      "Starting 36063\n",
      "Complete with 36063\n",
      "Starting 36065\n",
      "Complete with 36065\n",
      "Starting 36067\n",
      "Complete with 36067\n",
      "Starting 36069\n",
      "Complete with 36069\n",
      "Starting 36071\n",
      "Complete with 36071\n",
      "Starting 36073\n",
      "Complete with 36073\n",
      "Starting 36075\n",
      "Complete with 36075\n",
      "Starting 36077\n",
      "Complete with 36077\n",
      "Starting 36079\n",
      "Complete with 36079\n",
      "Starting 36083\n",
      "Complete with 36083\n",
      "Starting 36087\n",
      "Complete with 36087\n",
      "Starting 36089\n",
      "Complete with 36089\n",
      "Starting 36091\n",
      "Complete with 36091\n",
      "Starting 36093\n",
      "Complete with 36093\n",
      "Starting 36095\n",
      "Complete with 36095\n",
      "Starting 36097\n",
      "Complete with 36097\n",
      "Starting 36099\n",
      "Complete with 36099\n",
      "Starting 36101\n",
      "Complete with 36101\n",
      "Starting 36103\n",
      "Complete with 36103\n",
      "Starting 36105\n",
      "Complete with 36105\n",
      "Starting 36107\n",
      "Complete with 36107\n",
      "Starting 36109\n",
      "Complete with 36109\n",
      "Starting 36111\n",
      "Complete with 36111\n",
      "Starting 36113\n",
      "Complete with 36113\n",
      "Starting 36115\n",
      "Complete with 36115\n",
      "Starting 36117\n",
      "Complete with 36117\n",
      "Starting 36119\n",
      "Complete with 36119\n",
      "Starting 36121\n",
      "Complete with 36121\n",
      "Starting 36123\n",
      "Complete with 36123\n",
      "Starting New York City\n",
      "Complete with New York City\n",
      "Starting 12001\n",
      "Complete with 12001\n",
      "Starting 12003\n",
      "Complete with 12003\n",
      "Starting 12005\n",
      "Complete with 12005\n",
      "Starting 12007\n",
      "Complete with 12007\n",
      "Starting 12009\n",
      "Complete with 12009\n",
      "Starting 12011\n",
      "Complete with 12011\n",
      "Starting 12013\n",
      "Complete with 12013\n",
      "Starting 12015\n",
      "Complete with 12015\n",
      "Starting 12017\n",
      "Complete with 12017\n",
      "Starting 12019\n",
      "Complete with 12019\n",
      "Starting 12021\n",
      "Complete with 12021\n",
      "Starting 12023\n",
      "Complete with 12023\n",
      "Starting 12027\n",
      "Complete with 12027\n",
      "Starting 12029\n",
      "Complete with 12029\n",
      "Starting 12031\n",
      "Complete with 12031\n",
      "Starting 12033\n",
      "Complete with 12033\n",
      "Starting 12035\n",
      "Complete with 12035\n",
      "Starting 12037\n",
      "Complete with 12037\n",
      "Starting 12039\n",
      "Complete with 12039\n",
      "Starting 12041\n",
      "Complete with 12041\n",
      "Starting 12043\n",
      "Complete with 12043\n",
      "Starting 12047\n",
      "Complete with 12047\n",
      "Starting 12049\n",
      "Complete with 12049\n",
      "Starting 12051\n",
      "Complete with 12051\n",
      "Starting 12053\n",
      "Complete with 12053\n",
      "Starting 12055\n",
      "Complete with 12055\n",
      "Starting 12057\n",
      "Complete with 12057\n",
      "Starting 12059\n",
      "Complete with 12059\n",
      "Starting 12061\n",
      "Complete with 12061\n",
      "Starting 12063\n",
      "Complete with 12063\n",
      "Starting 12065\n",
      "Complete with 12065\n",
      "Starting 12067\n",
      "Complete with 12067\n",
      "Starting 12069\n",
      "Complete with 12069\n",
      "Starting 12071\n",
      "Complete with 12071\n",
      "Starting 12073\n",
      "Complete with 12073\n",
      "Starting 12075\n",
      "Complete with 12075\n",
      "Starting 12077\n",
      "Complete with 12077\n",
      "Starting 12079\n",
      "Complete with 12079\n",
      "Starting 12081\n",
      "Complete with 12081\n",
      "Starting 12083\n",
      "Complete with 12083\n",
      "Starting 12085\n",
      "Complete with 12085\n",
      "Starting 12086\n",
      "Complete with 12086\n",
      "Starting 12087\n",
      "Complete with 12087\n",
      "Starting 12089\n",
      "Complete with 12089\n",
      "Starting 12091\n",
      "Complete with 12091\n",
      "Starting 12093\n",
      "Complete with 12093\n",
      "Starting 12095\n",
      "Complete with 12095\n",
      "Starting 12097\n",
      "Complete with 12097\n",
      "Starting 12099\n",
      "Complete with 12099\n",
      "Starting 12101\n",
      "Complete with 12101\n",
      "Starting 12103\n",
      "Complete with 12103\n",
      "Starting 12105\n",
      "Complete with 12105\n",
      "Starting 12107\n",
      "Complete with 12107\n",
      "Starting 12109\n",
      "Complete with 12109\n",
      "Starting 12111\n",
      "Complete with 12111\n",
      "Starting 12113\n",
      "Complete with 12113\n",
      "Starting 12115\n",
      "Complete with 12115\n",
      "Starting 12117\n",
      "Complete with 12117\n",
      "Starting 12119\n",
      "Complete with 12119\n",
      "Starting 12121\n",
      "Complete with 12121\n",
      "Starting 12123\n",
      "Complete with 12123\n",
      "Starting 12125\n",
      "Complete with 12125\n",
      "Starting 12127\n",
      "Complete with 12127\n",
      "Starting 12129\n",
      "Complete with 12129\n",
      "Starting 12131\n",
      "Complete with 12131\n",
      "Starting 12133\n",
      "Complete with 12133\n"
     ]
    }
   ],
   "source": [
    "# conduct a forecast for all the counties in NY that there exists survey data for\n",
    "state_list = ['NY', 'FL']\n",
    "\n",
    "left = K0 + datetime.timedelta(days=7)\n",
    "right = datetime.date(2020, 12, 8) + datetime.timedelta(days=7)\n",
    "shifted_range = pd.date_range(start=left, end=right)\n",
    "numLoop = 5\n",
    "\n",
    "for state in state_list:\n",
    "    df_index = []\n",
    "    err_data = []\n",
    "\n",
    "    predictions_case_only = pd.DataFrame()\n",
    "    predictions_smell_0delay = pd.DataFrame()\n",
    "    predictions_hh_0delay = pd.DataFrame()\n",
    "\n",
    "    predictions_ihme = pd.DataFrame()\n",
    "    predictions_naive = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    if state == 'NY':\n",
    "        seiir_data = seiir_ny\n",
    "        county_list = ny_counties\n",
    "    else:\n",
    "        seiir_data = seiir_fl\n",
    "        county_list = fl_counties\n",
    "\n",
    "    for each in county_list:\n",
    "        if each == 'New York City':\n",
    "            fips = 'New York City'\n",
    "        else:\n",
    "            fips = data_sets.get_fips(state, each)\n",
    "            if (fips not in hh_data.index.levels[0]) or (fips not in smell_data.index.levels[1]):\n",
    "                continue\n",
    "\n",
    "        print('Starting', fips)\n",
    "\n",
    "        # dictionary to hold error for each forecast: our 3 versions, ihme, and naive\n",
    "        county_data = {}\n",
    "\n",
    "\n",
    "        # pandas series to hold the predictions that will be averaged\n",
    "        conf_avg = pd.Series(data=np.zeros(len(prediction_index)), index=prediction_index, dtype='float64')\n",
    "        ihme_avg = pd.Series(data=np.zeros(len(prediction_index)), index=prediction_index, dtype='float64')\n",
    "        for i in range(numLoop):\n",
    "            predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state, each, seiir_data, smell_data, hh_data, case_data, measure=None, K0=K0, delay=0)\n",
    "            conf_avg += predicted_case\n",
    "            ihme_avg += predicted_seiir_prior\n",
    "        # store the averaged predictions in their DataFrames (ihme only needs to be done once)\n",
    "        predictions_case_only[fips] = conf_avg / numLoop\n",
    "        predictions_ihme[fips] = ihme_avg / numLoop\n",
    "        # store the mean mse in the dictionary\n",
    "        county_data['mse_confirmed-only'] = calc_mse(predictions_case_only[fips].loc[left:right], case_ma7_all.loc[left:right])\n",
    "        county_data['ihme'] = calc_mse(predictions_ihme[fips].loc[left:right], case_ma7_all.loc[left:right])\n",
    "\n",
    "\n",
    "\n",
    "        smell0_avg = pd.Series(data=np.zeros(len(prediction_index)), index=prediction_index, dtype='float64')\n",
    "        for i in range(numLoop):\n",
    "            predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state, each, seiir_data, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=0)\n",
    "            smell0_avg += predicted_case\n",
    "        predictions_smell_0delay[fips] = smell0_avg / numLoop\n",
    "        county_data['mse_smell-0delay'] = calc_mse(predictions_smell_0delay[fips].loc[left:right], case_ma7_all.loc[left:right])\n",
    "\n",
    "\n",
    "        hh0_avg = pd.Series(data=np.zeros(len(prediction_index)), index=prediction_index, dtype='float64')\n",
    "        for i in range(numLoop):\n",
    "            predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state, each, seiir_data, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=0)\n",
    "            hh0_avg += predicted_case\n",
    "        predictions_hh_0delay[fips] = hh0_avg / numLoop\n",
    "        county_data['mse_hh-0delay'] = calc_mse(predictions_hh_0delay[fips].loc[left:right], case_ma7_all.loc[left:right])\n",
    "\n",
    "\n",
    "        # naive prediction\n",
    "        naive_pred = case_ma7_all.loc[left-datetime.timedelta(days=7):right-datetime.timedelta(days=7)].copy()\n",
    "        naive_pred.index = shifted_range\n",
    "        # store for future use\n",
    "        predictions_naive[fips] = naive_pred\n",
    "        # compute error\n",
    "        county_data['naive'] = calc_mse(naive_pred.loc[left:right], case_ma7_all.loc[left:right])\n",
    "\n",
    "\n",
    "        df_index.append(fips)\n",
    "        err_data.append(county_data)\n",
    "        print('Complete with', fips)\n",
    "        \n",
    "    err_df = pd.DataFrame(err_data, index=df_index)\n",
    "    if state == 'NY':\n",
    "        err_df.to_csv(r'output/err_ny_20201208.csv')\n",
    "        predictions_case_only.to_csv(r'output/pred_ny_case_only.csv')\n",
    "        predictions_smell_0delay.to_csv(r'output/pred_ny_smell_0delay.csv')\n",
    "        predictions_hh_0delay.to_csv(r'output/pred_ny_hh_0delay.csv')\n",
    "\n",
    "        predictions_ihme.to_csv(r'output/pred_ny_ihme.csv')\n",
    "        predictions_naive.to_csv(r'output/pred_ny_naive.csv')\n",
    "    else:\n",
    "        err_df.to_csv(r'output/err_fl_20201208.csv')\n",
    "        predictions_case_only.to_csv(r'output/pred_fl_case_only.csv')\n",
    "        predictions_smell_0delay.to_csv(r'output/pred_fl_smell_0delay.csv')\n",
    "        predictions_hh_0delay.to_csv(r'output/pred_fl_hh_0delay.csv')\n",
    "\n",
    "        predictions_ihme.to_csv(r'output/pred_fl_ihme.csv')\n",
    "        predictions_naive.to_csv(r'output/pred_fl_naive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_hh_0delay[fips].loc[left:right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All plotting code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "county = 'Westchester'\n",
    "state_2l = 'NY'\n",
    "if state_2l == 'NY':\n",
    "    the_seiir = seiir_ny\n",
    "else:\n",
    "    the_seiir = seiir_fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "if county == 'New York City':\n",
    "    county_pop = 0\n",
    "    for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "        this_count, state_pop = data_sets.get_pops(each)\n",
    "        county_pop += this_count\n",
    "else:\n",
    "    county_pop, state_pop = data_sets.get_pops(data_sets.get_fips(state_2l, county))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967506"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19453561"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "county_preds = {}\n",
    "survey_data = {}\n",
    "estimates = ['confirmed_only', 'hh_delay0', 'smell_delay0']\n",
    "measure_type = [None, 'hh', 'smell']\n",
    "#delay_list = [0, 0, 0]\n",
    "for i in range(len(estimates)):\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2l, county, the_seiir, smell_data, hh_data, case_data, measure=measure_type[i], K0=datetime.date(2020, 4, 18), delay=0)\n",
    "    survey_data[estimates[i]] = num_survey_ma7\n",
    "    county_preds[estimates[i]] = predicted_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate_type = ['hh_delay6', 'confirmed_only', 'hh_delay0', 'smell_delay0', 'smell_delay6']\n",
    "labels = ['Forecast using Case Count Only', 'Forecast Case Count w/ Household Symptoms', 'Forecast Case Count w/ Loss of Smell/Taste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "d = datetime.date(2020, 10, 23)\n",
    "gold_right = d + datetime.timedelta(days=7)\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=K0, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i in range(len(estimates)):\n",
    "    plt.plot(county_preds[estimates[i]].index, county_preds[estimates[i]], label=labels[i], c=colors[i])\n",
    "plt.plot(case_ma7_all.loc[K0:gold_right].index, case_ma7_all.loc[K0:gold_right], label='Actual Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior, label='IHME Forecast', c=)\n",
    "\n",
    "\n",
    "#naieve estimate\n",
    "naive_start = K0 + datetime.timedelta(days=7)\n",
    "naive_d = d + datetime.timedelta(days=7)\n",
    "plt.plot(case_ma7_all.loc[naive_start:naive_d].index, case_ma7_all.loc[K0:d], label='Naive Estimate', c='orange')\n",
    "plt.legend(loc='upper center')\n",
    "plt.xticks(rotation=30, ha='right', rotation_mode='anchor')\n",
    "#plt.ylim(2700, 3055)\n",
    "#plt.xlim(datetime.date(2020, 7, 25), datetime.date(2020, 7, 30))\n",
    "\n",
    "\n",
    "#plt.title(county)\n",
    "plt.ylabel('Number of Cases per Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_vals.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K_vals.index, K_vals)\n",
    "plt.title('Miami-Dade hh6 K[4, 4] Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim_left = datetime.date(2020, 6, 1)\n",
    "xlim_right = None\n",
    "\n",
    "leftylim_low = None\n",
    "leftylim_high = None\n",
    "\n",
    "rightylim_low = None\n",
    "rightylim_high = None\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot findings -- multiple plots\n",
    "\n",
    "# Plotting constants and variables ----------------\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "purple = '#33016F'\n",
    "bright_purp = '#9400D3'\n",
    "light_purp = '#BF9BDE'\n",
    "gold = '#9E7A27'\n",
    "gray = '#797979'\n",
    "bright_orange = '#FE5000'\n",
    "width = 3\n",
    "xtick_size = 14\n",
    "xlabel_size = 14\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = datetime.date(2020, 12, 8)\n",
    "K0 = datetime.date(2020, 4, 18)\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "end = d + datetime.timedelta(days=7)\n",
    "\n",
    "week_interval = pd.date_range(start=K0, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "#start = datetime.date(2020, 6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_data = data_sets.create_case_df_county()\n",
    "\n",
    "def get_case_count(case_df, state_2L, county):\n",
    "    if county == 'New York City':\n",
    "        fips = 'New York City'\n",
    "    else:\n",
    "        fips = data_sets.get_fips(state_2L, county)\n",
    "    case_data_geo = case_df.loc[fips]['case_rate'].copy()\n",
    "    case_ma7 = case_data_geo.rolling(window=7).mean()\n",
    "    case_ma7_all = case_ma7.iloc[6:]\n",
    "    return case_ma7_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = 'Miami-Dade'\n",
    "state_2L = 'FL'\n",
    "if county == 'New York City':\n",
    "    fips = 'New York City'\n",
    "else:\n",
    "    fips = data_sets.get_fips(state_2L, county)\n",
    "case_ma7_all = get_case_count(case_data, state_2L, county)\n",
    "\n",
    "ihme_pred_all = pd.read_csv(r'output/pred_fl_ihme.csv', index_col=0, parse_dates=True)\n",
    "case_only_pred_all = pd.read_csv(r'output/pred_fl_case_only.csv', index_col=0, parse_dates=True)\n",
    "smell_pred_all = pd.read_csv(r'output/pred_fl_smell_0delay.csv', index_col=0, parse_dates=True)\n",
    "hh_pred_all = pd.read_csv(r'output/pred_fl_hh_0delay.csv', index_col=0, parse_dates=True)\n",
    "naive_pred_all = pd.read_csv(r'output/pred_fl_naive.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "ihme_pred = ihme_pred_all[fips]\n",
    "case_only_pred = case_only_pred_all[fips]\n",
    "smell_pred = smell_pred_all[fips]\n",
    "hh_pred = hh_pred_all[fips]\n",
    "naive_pred = naive_pred_all[fips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-04-25    401.939024\n",
       "2020-04-26    397.863143\n",
       "2020-04-27    398.946760\n",
       "2020-04-28    396.130424\n",
       "2020-04-29    388.652286\n",
       "                 ...    \n",
       "2020-12-11    987.801984\n",
       "2020-12-12    980.318146\n",
       "2020-12-13    983.041013\n",
       "2020-12-14    984.962793\n",
       "2020-12-15    988.115749\n",
       "Name: 12086, Length: 235, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihme_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-100, 3600)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This is the one plot\n",
    "\n",
    "start = K0 + datetime.timedelta(days=7)\n",
    "end = d + datetime.timedelta(days=7)\n",
    "\n",
    "fig4, ax41 = plt.subplots(1)\n",
    "plt.sca(ax41)\n",
    "plt.plot(case_ma7_all.loc[K0:end].index, case_ma7_all.loc[K0:end], label='Actual Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(ihme_pred.loc[start:end].index, ihme_pred.loc[start:end], label='IHME 7-day Forecast', c=gray,\n",
    "         linewidth=width)\n",
    "plt.plot(naive_pred.loc[start:end].index, naive_pred.loc[start:end], label='Naive Estimate', c=bright_orange,\n",
    "         linewidth=width)\n",
    "\n",
    "plt.plot(case_only_pred.loc[start:end].index, case_only_pred.loc[start:end], label='7-Day Forecast using Case Count Only',\n",
    "         linewidth=width-1, c=purple)\n",
    "plt.plot(smell_pred.loc[start:end].index, smell_pred.loc[start:end], label='7-Day Forecast Case Count w/ Loss of Smell/Taste',\n",
    "         linewidth=width-1, c=bright_purp)\n",
    "plt.plot(hh_pred.loc[start:end].index, hh_pred.loc[start:end], label='7-Day Forecast Case Count w/ Household Symptoms',\n",
    "         linewidth=width-1, c=light_purp)\n",
    "\n",
    "\"\"\"\n",
    "ax42 = ax41.twinx()\n",
    "plt.sca(ax42)\n",
    "plt.plot(survey_data['hh_delay0'].loc[K0:end].index, survey_data['hh_delay0'].loc[K0:end], c='red',\n",
    "         label='Count of Household Symptom Response', linewidth=width-1)\n",
    "plt.plot(survey_data['smell_delay0'].loc[K0:end].index, survey_data['smell_delay0'].loc[K0:end], c='maroon',\n",
    "         label='Count of Loss of Smell Response', linewidth=width-1)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Responses per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\"\"\"\n",
    "\n",
    "#plt.sca(ax41)\n",
    "\"\"\"\n",
    "plt.plot(predicted_case.index, predicted_case.loc[K0:], label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(-100, 3600)\n",
    "#plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "#plt.title('Miami-Dade, Household Symptoms, delay of 6 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_preds[estimates[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_ny_state = pd.read_csv(r'data/seiir_projections/new_york_proj.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>E</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>R</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>1.979023e+07</td>\n",
       "      <td>106.854381</td>\n",
       "      <td>25.532244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-11</th>\n",
       "      <td>1.979019e+07</td>\n",
       "      <td>135.370375</td>\n",
       "      <td>34.165081</td>\n",
       "      <td>5.735700</td>\n",
       "      <td>1.868136e+00</td>\n",
       "      <td>3.828568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-12</th>\n",
       "      <td>1.979014e+07</td>\n",
       "      <td>163.677532</td>\n",
       "      <td>44.895678</td>\n",
       "      <td>12.645587</td>\n",
       "      <td>6.414865e+00</td>\n",
       "      <td>3.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>1.979009e+07</td>\n",
       "      <td>185.941663</td>\n",
       "      <td>55.374704</td>\n",
       "      <td>20.009029</td>\n",
       "      <td>1.385817e+01</td>\n",
       "      <td>2.621240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14</th>\n",
       "      <td>1.979004e+07</td>\n",
       "      <td>209.578200</td>\n",
       "      <td>66.865630</td>\n",
       "      <td>28.139395</td>\n",
       "      <td>2.479945e+01</td>\n",
       "      <td>2.268072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>1.258239e+07</td>\n",
       "      <td>6212.135951</td>\n",
       "      <td>3087.113438</td>\n",
       "      <td>2385.406004</td>\n",
       "      <td>7.196296e+06</td>\n",
       "      <td>0.872742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>1.258052e+07</td>\n",
       "      <td>6413.925937</td>\n",
       "      <td>3187.020352</td>\n",
       "      <td>2464.107692</td>\n",
       "      <td>7.197785e+06</td>\n",
       "      <td>0.874872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>1.257859e+07</td>\n",
       "      <td>6622.087015</td>\n",
       "      <td>3290.015767</td>\n",
       "      <td>2545.245365</td>\n",
       "      <td>7.199323e+06</td>\n",
       "      <td>0.876996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>1.257659e+07</td>\n",
       "      <td>6836.762379</td>\n",
       "      <td>3396.203136</td>\n",
       "      <td>2628.918289</td>\n",
       "      <td>7.200911e+06</td>\n",
       "      <td>0.879116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>1.257454e+07</td>\n",
       "      <td>7057.146142</td>\n",
       "      <td>3505.600545</td>\n",
       "      <td>2715.210083</td>\n",
       "      <td>7.202550e+06</td>\n",
       "      <td>0.880329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       S            E           I1           I2             R  \\\n",
       "date                                                                            \n",
       "2020-02-10  1.979023e+07   106.854381    25.532244     0.000000  0.000000e+00   \n",
       "2020-02-11  1.979019e+07   135.370375    34.165081     5.735700  1.868136e+00   \n",
       "2020-02-12  1.979014e+07   163.677532    44.895678    12.645587  6.414865e+00   \n",
       "2020-02-13  1.979009e+07   185.941663    55.374704    20.009029  1.385817e+01   \n",
       "2020-02-14  1.979004e+07   209.578200    66.865630    28.139395  2.479945e+01   \n",
       "...                  ...          ...          ...          ...           ...   \n",
       "2021-12-27  1.258239e+07  6212.135951  3087.113438  2385.406004  7.196296e+06   \n",
       "2021-12-28  1.258052e+07  6413.925937  3187.020352  2464.107692  7.197785e+06   \n",
       "2021-12-29  1.257859e+07  6622.087015  3290.015767  2545.245365  7.199323e+06   \n",
       "2021-12-30  1.257659e+07  6836.762379  3396.203136  2628.918289  7.200911e+06   \n",
       "2021-12-31  1.257454e+07  7057.146142  3505.600545  2715.210083  7.202550e+06   \n",
       "\n",
       "                beta  \n",
       "date                  \n",
       "2020-02-10  5.000033  \n",
       "2020-02-11  3.828568  \n",
       "2020-02-12  3.065767  \n",
       "2020-02-13  2.621240  \n",
       "2020-02-14  2.268072  \n",
       "...              ...  \n",
       "2021-12-27  0.872742  \n",
       "2021-12-28  0.874872  \n",
       "2021-12-29  0.876996  \n",
       "2021-12-30  0.879116  \n",
       "2021-12-31  0.880329  \n",
       "\n",
       "[691 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihme_ny_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d00b276ac8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_start = predicted_seiir_prior.index[0]\n",
    "gray_end = predicted_seiir_prior.index[-1]\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.plot(ihme_ny_state.loc[gray_start:gray_end].index, ihme_ny_state['I2'].loc[gray_start:gray_end],\n",
    "         label='IHME State I2')\n",
    "plt.title('Nassau, b = 0.06975')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC plot settings\n",
    "\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -400\n",
    "leftylim_high = 7500\n",
    "\n",
    "rightylim_low = -3\n",
    "rightylim_high = 57\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nassau plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -66\n",
    "leftylim_high = 1000\n",
    "\n",
    "rightylim_low = -.3\n",
    "rightylim_high = 8\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Westchester plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -28\n",
    "leftylim_high = 700\n",
    "\n",
    "rightylim_low = -.5\n",
    "rightylim_high = 17\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albany plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -6\n",
    "leftylim_high = 110\n",
    "\n",
    "rightylim_low = -.125\n",
    "rightylim_high = 3.8\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erie plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -10\n",
    "leftylim_high = 280\n",
    "\n",
    "rightylim_low = -.8\n",
    "rightylim_high = 22\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
