{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs an extended Kalman filter using IHME SEIIR predictions along with measurement data of confirmed Covid-19 case counts (from New York Times data) and Facebook symptom data (loss of smell/taste, from Covid-19 Symptom Challenge) to generate updated 7-day predictions of case counts for counties in New York State.\n",
    "\n",
    "Developed by the University of Washington team of Les Atlas, Abraham Flaxman and Michael Rhoads.\n",
    "\n",
    "S - Susceptible\n",
    "E - Exposed\n",
    "I1 - Presymptomatic\n",
    "I2 - Symptomatic\n",
    "R - Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_sets\n",
    "import seiir_compartmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to support the Kalman filtering\n",
    "def get_predicts_prior(day, seiir):\n",
    "    x_hat = np.array([[seiir['S'].loc[day]],\n",
    "                      [seiir['E'].loc[day]],\n",
    "                      [seiir['I1'].loc[day]],\n",
    "                      [seiir['I2'].loc[day]],\n",
    "                      [seiir['R'].loc[day]]])\n",
    "\n",
    "    beta_k = seiir['beta'].loc[day]\n",
    "\n",
    "    return x_hat, beta_k\n",
    "\n",
    "\n",
    "def step_seiir(x_hat, constants, beta_k, days=7):\n",
    "    s_dict = {'S': x_hat[0, 0],\n",
    "              'E': x_hat[1, 0],\n",
    "              'I1': x_hat[2, 0],\n",
    "              'I2': x_hat[3, 0],\n",
    "              'R': x_hat[4, 0]}\n",
    "\n",
    "    s = pd.Series(s_dict)\n",
    "\n",
    "    for i in range(days):\n",
    "        infectious = s.loc['I1'] + s.loc['I2']\n",
    "        s = seiir_compartmental.compartmental_covid_step(s, s.sum(),\n",
    "                                                         infectious,\n",
    "                                                         constants['alpha'],\n",
    "                                                         beta_k,\n",
    "                                                         constants['gamma1'],\n",
    "                                                         constants['gamma2'],\n",
    "                                                         constants['sigma'],\n",
    "                                                         constants['theta'])\n",
    "    x_hat_future_prior = np.array([[s.loc['S']],\n",
    "                                   [s.loc['E']],\n",
    "                                   [s.loc['I1']],\n",
    "                                   [s.loc['I2']],\n",
    "                                   [s.loc['R']]])\n",
    "\n",
    "    return x_hat_future_prior\n",
    "\n",
    "\n",
    "def predict_step(x_hat_k1_prior, P, Q, beta_k, constants):\n",
    "    S = x_hat_k1_prior[0, 0]\n",
    "    E = x_hat_k1_prior[1, 0]\n",
    "    I1 = x_hat_k1_prior[2, 0]\n",
    "    I2 = x_hat_k1_prior[3, 0]\n",
    "    R = x_hat_k1_prior[4, 0]\n",
    "    N = S + E + I1 + I2 + R\n",
    "    alpha = constants['alpha']\n",
    "    sigma = constants['sigma']\n",
    "    gamma1 = constants['gamma1']\n",
    "    gamma2 = constants['gamma2']\n",
    "\n",
    "    part_f_S = np.array([[-beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_E = np.array([[0],\n",
    "                         [-sigma],\n",
    "                         [sigma],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_I1 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [-gamma1],\n",
    "                          [gamma1],\n",
    "                          [0]])\n",
    "\n",
    "    part_f_I2 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [0],\n",
    "                          [-gamma2],\n",
    "                          [gamma2]])\n",
    "    \n",
    "    part_f_R = np.array([[0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    # 5x5\n",
    "    f_jacob = np.concatenate([part_f_S, part_f_E, part_f_I1, part_f_I2,\n",
    "                              part_f_R], axis=1)\n",
    "\n",
    "    \"\"\"\n",
    "    print('f_jacob =')\n",
    "    print(f_jacob)\n",
    "    print('f_jacob[4,4] =', f_jacob[3, 3])\n",
    "    \"\"\"\n",
    "    # 5x5\n",
    "    # P_prior = f_jacob * P * f_jacob^T + Q\n",
    "    P_prior = np.matmul(np.matmul(f_jacob, P), f_jacob.T) + Q\n",
    "    \n",
    "    \"\"\"\n",
    "    print()\n",
    "    print('P prior - in predict step =')\n",
    "    print(P_prior)\n",
    "    print('P_prior[4,4] =', P_prior[3, 3])\n",
    "    print()\n",
    "    print()\n",
    "    \"\"\"\n",
    "    return P_prior\n",
    "\n",
    "\n",
    "def update_step(x_hat, x_hat_k1, P_prior, Rn, rho1, rho2, z_k, measure):\n",
    "    # 5x5\n",
    "    ep = 10**-8\n",
    "    if measure is None:\n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, 0, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    else:\n",
    "                \n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, rho1, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    \n",
    "    \n",
    "    # Si = H * P_prior * H^T + Rn\n",
    "    Si = np.matmul(np.matmul(H, P_prior), H.T) + Rn\n",
    "\n",
    "    # K = P_prior * H.T (H * P_prior * H.T + R)^-1\n",
    "    # K_new = P_prior * H^T * Si^(-1)\n",
    "    K_new = np.matmul(np.matmul(P_prior, H.T), np.linalg.inv(Si))\n",
    "    \n",
    "    y_new = np.matmul(H, x_hat)\n",
    "\n",
    "    # 5x1\n",
    "    diff = z_k - y_new\n",
    "\n",
    "    x_hat_k1_post = x_hat_k1 + np.matmul(K_new, diff)\n",
    "\n",
    "    P_post = P_prior - np.matmul(np.matmul(K_new, Si), K_new.T)\n",
    "\n",
    "\n",
    "    return x_hat_k1_post, P_post, diff, K_new[3, 3]\n",
    "\n",
    "\n",
    "def create_data_sets():\n",
    "    seiir_fl = pd.read_csv(r'data/seiir_projections/florida_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "\n",
    "    seiir_ny = pd.read_csv(r'data/seiir_projections/new_york_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "    \n",
    "    smell_data = data_sets.create_symptom_df()\n",
    "    \n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    \n",
    "    return seiir_fl, seiir_ny, smell_data, case_data\n",
    "\n",
    "\n",
    "def get_smell_data(fips, fb_data):\n",
    "\n",
    "    if fips == 'New York City':\n",
    "        nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "        fb_data_geo = fb_data.loc[(slice(None), '36081'), :].copy()\n",
    "        fb_data_geo = fb_data_geo.mean(level='date')\n",
    "\n",
    "        for borough in nyc_fips:\n",
    "            fb_data_geo += fb_data.loc[(slice(None), borough), :].copy().mean(level='date')\n",
    "\n",
    "    else:\n",
    "        fb_data_geo = fb_data.loc[(slice(None), fips), :].copy()\n",
    "\n",
    "        # collapse down to a single index column (date)\n",
    "        fb_data_geo.index = fb_data_geo.index.droplevel([0, 1])\n",
    "\n",
    "    return fb_data_geo\n",
    "    \n",
    "\n",
    "\n",
    "def calc_fb_ma7(fb_data):\n",
    "    \"\"\"\n",
    "    Returns a Pandas series\n",
    "    \"\"\"\n",
    "    # the fb_data is a DataFrame while the case_data is a Series\n",
    "    fb_ma7 = fb_data.rolling(window=7).mean()\n",
    "    fb_ma7 = fb_ma7.iloc[6:, :]\n",
    "    prop_ma7 = fb_ma7['num_stl'].div(fb_ma7['n'])\n",
    "\n",
    "    return prop_ma7, fb_ma7['n'].copy(), fb_ma7['num_stl'].copy()\n",
    "\n",
    "\n",
    "def calc_mse(prediction, actual):\n",
    "    \"\"\"\n",
    "    Inputs should be two Pandas Series of same length.\n",
    "    Outputs a float.\n",
    "    \"\"\"\n",
    "    err = prediction - actual\n",
    "    sum_sq_err = (err**2).sum()\n",
    "    mse = sum_sq_err / err.count()\n",
    "    return mse\n",
    "\n",
    "\n",
    "def create_hh_data():\n",
    "    # bring in new data\n",
    "    full_data = pd.read_csv(r'data/from_challenge/overall-county.csv', header=0, dtype={'fips': 'str', 'pct_hh_cli': 'float64'},\n",
    "                            parse_dates=[0])\n",
    "    time_start = full_data['date'].min()\n",
    "    time_end = full_data['date'].max()\n",
    "    full_data.set_index(['fips', 'date'], inplace=True)\n",
    "    full_data.sort_index(inplace=True)\n",
    "\n",
    "    # derive count of survey respondents with household members having covid symptoms\n",
    "    full_data['num_hh_cli'] = full_data['n'].mul(full_data['pct_hh_cli']/100.).round()\n",
    "    full_data['num_hh_cli'] = full_data['num_hh_cli'].astype('int64')\n",
    "\n",
    "    # group by county and date\n",
    "    data_of_interest = full_data[['n', 'num_hh_cli']].copy().groupby(level=(0, 1)).sum()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    # create full date range\n",
    "    date_rng = pd.date_range(time_start, time_end)\n",
    "    iterables = [data_of_interest.index.levels[0], date_rng]\n",
    "    new_index = pd.MultiIndex.from_product(iterables, names=['fips', 'date'])\n",
    "\n",
    "    data_of_interest = data_of_interest.reindex(index=new_index)\n",
    "    # this will have NaN values in the new index entries for which there was no\n",
    "    # previous data -- fill them upon extracting a particular county\n",
    "    \n",
    "    return data_of_interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_county_lists():\n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    ny_counties = case_data[case_data['state'] == 'New York']['county'].unique()\n",
    "    fl_counties = case_data[case_data['state'] == 'Florida']['county'].unique()\n",
    "    return ny_counties, fl_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seiir_fl, seiir_ny, smell_data, case_data = create_data_sets()\n",
    "\n",
    "hh_data = create_hh_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_county(the_state, county_name, seiir, smell_data, hh_data, case_data, measure='smell', K0=datetime.date(2020, 4, 18), delay=6):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        measure -- potential values are: 'smell', 'hh', or None\n",
    "    \"\"\"\n",
    "    # set constants\n",
    "    #K0 = datetime.date(2020, 4, 12)\n",
    "\n",
    "    if county_name == 'New York City':\n",
    "        the_county = county_name\n",
    "    else:\n",
    "        the_county = data_sets.get_fips(the_state, county_name)\n",
    "\n",
    "    constants = {\n",
    "        'alpha': 0.948786,\n",
    "        'gamma1': 0.500000,\n",
    "        'gamma2': 0.662215,\n",
    "        'sigma': 0.266635,\n",
    "        'theta': 6.000000\n",
    "        }\n",
    "\n",
    "    # set initial values for Kalman filter parameters\n",
    "    P_mult = 1\n",
    "    Q_mult = 1\n",
    "\n",
    "    # Rn is the R noise covariance matrix; it remains constant thru the stepping of the\n",
    "    # Kalman filter\n",
    "    Rn_mult = 5*10**-8\n",
    "\n",
    "    Rn_22 = 10000\n",
    "    Rn_32 = 1000\n",
    "\n",
    "    Rn_23 = 1000\n",
    "    Rn_33 = 100\n",
    "\n",
    "    Rn = Rn_mult * np.array([[0, 0, 0, 0, 0],\n",
    "                             [0, 0, 0, 0, 0],\n",
    "                             [0, 0, Rn_22, Rn_23, 0],\n",
    "                             [0, 0, Rn_32, Rn_33, 0],\n",
    "                             [0, 0, 0, 0, 0]])\n",
    "\n",
    "    Q = Q_mult * np.eye(5)\n",
    "    P = P_mult * np.eye(5)\n",
    "    \n",
    "    if the_county == 'New York City':\n",
    "        county_pop = 0\n",
    "        for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "            this_count, state_pop = data_sets.get_pops(each)\n",
    "            county_pop += this_count\n",
    "    else:\n",
    "        county_pop, state_pop = data_sets.get_pops(the_county)\n",
    "\n",
    "    b = county_pop / state_pop\n",
    "\n",
    "    # generate data\n",
    "    case_data_geo = case_data.loc[the_county]['case_rate'].copy()\n",
    "    smell_data_geo = get_smell_data(the_county, smell_data)\n",
    "    \n",
    "\n",
    "    if measure == 'hh':\n",
    "        idx = pd.IndexSlice\n",
    "        \n",
    "        if the_county == 'New York City':\n",
    "            nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "            hh_cli = hh_data.loc[idx['36081', :], :].loc['36081'].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "            for borough in nyc_fips:\n",
    "                bor_hh_cli = hh_data.loc[idx[borough, :], :].loc[borough].copy()\n",
    "                bor_hh_cli.fillna(method='pad', inplace=True)\n",
    "                hh_cli += bor_hh_cli\n",
    "\n",
    "        else:\n",
    "            hh_cli = hh_data.loc[idx[the_county, :], :].loc[the_county].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "        # calculate moving averages on the fb and case data\n",
    "        hh_cli_ma7 = hh_cli.rolling(window=7).mean()\n",
    "        hh_cli_ma7 = hh_cli_ma7.iloc[6:, :]\n",
    "        num_survey_ma7 = hh_cli_ma7['num_hh_cli']\n",
    "        prop_cli_ma7 = num_survey_ma7.div(hh_cli_ma7['n'])\n",
    "        \n",
    "    elif measure == 'smell':\n",
    "        prop_ma7, n_ma7, num_survey_ma7 = calc_fb_ma7(smell_data_geo)\n",
    "        \n",
    "    else:\n",
    "        num_survey_ma7 = None\n",
    "\n",
    "\n",
    "    case_ma7 = case_data_geo.rolling(window=7).mean()\n",
    "    case_ma7_all = case_ma7.iloc[6:]\n",
    "    \n",
    "\n",
    "    # get starting compartment values for the state level\n",
    "    x_hat_state_k0, beta_k0 = get_predicts_prior(K0, seiir)\n",
    "\n",
    "    # convert to the county level\n",
    "    x_hat_k0 = b * x_hat_state_k0\n",
    "\n",
    "    I2_county = x_hat_k0[3, 0]\n",
    "\n",
    "\n",
    "    rho1 = .05\n",
    "    rho2 = case_ma7_all.loc['2020-04-12'] / I2_county\n",
    "\n",
    "\n",
    "    # create empty dictionaries to hold the estimated values\n",
    "    case_est = {}\n",
    "    seiir_pred = {}\n",
    "\n",
    "    diff_rat = {}\n",
    "\n",
    "    K_val_dict = {}\n",
    "\n",
    "\n",
    "    # Original data run ----------------\n",
    "    start = K0\n",
    "    k = start\n",
    "\n",
    "    while k <= datetime.date(2020, 10, 23):    \n",
    "\n",
    "    # each cycle of the while loop executes a step\n",
    "\n",
    "        # get state level compartments\n",
    "        x_hat_state_k, beta_k = get_predicts_prior(k, seiir)\n",
    "\n",
    "        # step the state level compartments 1 day forward\n",
    "        x_hat_state_k1 = step_seiir(x_hat_state_k, constants, beta_k, days=1)\n",
    "        P = predict_step(x_hat_state_k, P, Q, beta_k, constants)\n",
    "        \n",
    "        # then 6 more\n",
    "        P_est = P.copy()\n",
    "        for i in range(6):\n",
    "            x_hat_est = step_seiir(x_hat_state_k1, constants, beta_k, days=1)\n",
    "            P_est = predict_step(x_hat_state_k1, P_est, Q, beta_k, constants)\n",
    "            x_hat_state_k1 = x_hat_est.copy()\n",
    "\n",
    "        # convert the state level compartments to county level values\n",
    "        x_hat_k = b * x_hat_state_k\n",
    "        x_hat_k1 = b * x_hat_state_k1\n",
    "\n",
    "        \n",
    "        indexDate = k + datetime.timedelta(days=7)\n",
    "        # store seiir prediction before it's modified by Kalman filter\n",
    "        seiir_pred[indexDate] = x_hat_k1[3, 0]\n",
    "\n",
    "        # get measurements for current day\n",
    "        if measure == 'smell':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_ma7.loc[k - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])    \n",
    "\n",
    "        elif measure == 'hh':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_cli_ma7.loc[k - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])\n",
    "            \n",
    "        else:\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [0],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])\n",
    "\n",
    "        # predict step using the stepped fwd SEIIR compartment values \n",
    "        #P = predict_step(x_hat_k1, P, Q, beta_k, constants)\n",
    "\n",
    "        # update step\n",
    "        x_hat_post, P_post, the_diff, K_val = update_step(x_hat_k, x_hat_k1, P_est, Rn,\n",
    "                                         rho1, rho2, z_k, measure)\n",
    "\n",
    "\n",
    "        # store estimated values for proportion and case rate\n",
    "        K_val_dict[indexDate] = K_val\n",
    "        case_est[indexDate] = rho2 * x_hat_post[3, 0]\n",
    "\n",
    "\n",
    "        diff_rat[indexDate] = the_diff[2, 0] / the_diff[3, 0]\n",
    "\n",
    "        # update the P and k\n",
    "        # comment out the P update because it has already been stepped once\n",
    "        #P = P_post\n",
    "        k += datetime.timedelta(days=1)\n",
    "\n",
    "    # create pandas series of the estimated case rate\n",
    "    predicted_case = pd.Series(case_est)\n",
    "    predicted_seiir_prior = pd.Series(seiir_pred)\n",
    "    K_val_series = pd.Series(K_val_dict)\n",
    "    \n",
    "    return predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_val_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('FL', 'Miami-Dade', seiir_fl, smell_data, hh_data, case_data, measure='smell', K0=datetime.date(2020, 4, 18), delay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "\n",
    "ny_counties, fl_counties = create_county_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_index = []\n",
    "err_data = []\n",
    "\n",
    "predictions_case_only = pd.DataFrame()\n",
    "predictions_smell_0delay = pd.DataFrame()\n",
    "predictions_smell_6delay = pd.DataFrame()\n",
    "predictions_hh_0delay = pd.DataFrame()\n",
    "predictions_hh_6delay = pd.DataFrame()\n",
    "\n",
    "left = K0 + datetime.timedelta(days=7)\n",
    "right = datetime.date(2020, 10, 23)\n",
    "shifted_range = pd.date_range(start=left, end=right)\n",
    "numLoop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in ny_counties:\n",
    "    if each == 'New York City':\n",
    "        fips = 'New York City'\n",
    "    else:\n",
    "        fips = data_sets.get_fips('NY', each)\n",
    "        if (fips not in hh_data.index.levels[0]) or (fips not in smell_data.index.levels[1]):\n",
    "            continue\n",
    "    \n",
    "    print('Starting', fips)\n",
    "    \n",
    "    county_data = {}\n",
    "    \n",
    "    conf_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure=None, K0=K0, delay=0)\n",
    "        conf_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_confirmed-only'] = conf_mses.mean()\n",
    "    county_data['ihme'] = calc_mse(predicted_seiir_prior.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    predictions_case_only[fips] = predicted_case\n",
    "    \n",
    "    \"\"\"\n",
    "    smell0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=0)\n",
    "        smell0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_smell-0delay'] = smell0_mses.mean()\n",
    "    predictions_smell_0delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    smell6_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=6)\n",
    "        smell6_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_smell-6delay'] = smell6_mses.mean()\n",
    "    predictions_smell_6delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    hh0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=0)\n",
    "        hh0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_hh-0delay'] = hh0_mses.mean()\n",
    "    predictions_hh_0delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    hh6_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=6)\n",
    "        hh6_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_hh-6delay'] = hh6_mses.mean()\n",
    "    predictions_hh_6delay[fips] = predicted_case\n",
    "    \n",
    "    naive_pred = case_ma7_all.loc[left-datetime.timedelta(days=7):right-datetime.timedelta(days=7)].copy()\n",
    "    naive_pred.index = shifted_range\n",
    "    county_data['naive'] = calc_mse(naive_pred.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \"\"\"\n",
    "    \n",
    "    df_index.append(fips)\n",
    "    err_data.append(county_data)\n",
    "    print('Complete with', fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_ny_df = pd.DataFrame(err_data, index=df_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_ny_df.to_csv(r'output/err_ny_ihme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_case_only.to_csv(r'output/pred_ny_case_only.csv')\n",
    "predictions_smell_0delay.to_csv(r'output/pred_ny_smell_0delay.csv')\n",
    "predictions_smell_6delay.to_csv(r'output/pred_ny_smell_6delay.csv')\n",
    "predictions_hh_0delay.to_csv(r'output/pred_ny_hh_0delay.csv')\n",
    "predictions_hh_6delay.to_csv(r'output/pred_ny_hh_6delay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = []\n",
    "err_data = []\n",
    "\n",
    "predictions_case_only = pd.DataFrame()\n",
    "predictions_smell_0delay = pd.DataFrame()\n",
    "predictions_smell_6delay = pd.DataFrame()\n",
    "predictions_hh_0delay = pd.DataFrame()\n",
    "predictions_hh_6delay = pd.DataFrame()\n",
    "\n",
    "left = K0 + datetime.timedelta(days=7)\n",
    "right = datetime.date(2020, 10, 23)\n",
    "shifted_range = pd.date_range(start=left, end=right)\n",
    "numLoop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_2L = 'FL'\n",
    "\n",
    "for each in fl_counties:\n",
    "    fips = data_sets.get_fips(state_2L, each)\n",
    "    if (fips not in hh_data.index.levels[0]) or (fips not in smell_data.index.levels[1]):\n",
    "        continue\n",
    "    \n",
    "    print('Starting', fips)\n",
    "    \n",
    "    county_data = {}\n",
    "    \n",
    "    conf_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure=None, K0=K0, delay=0)\n",
    "        conf_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['ihme'] = calc_mse(predicted_seiir_prior.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_confirmed-only'] = conf_mses.mean()\n",
    "    predictions_case_only[fips] = predicted_case\n",
    "    \n",
    "    \"\"\"\n",
    "    smell0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=0)\n",
    "        smell0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_smell-0delay'] = smell0_mses.mean()\n",
    "    predictions_smell_0delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    smell6_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=6)\n",
    "        smell6_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_smell-6delay'] = smell6_mses.mean()\n",
    "    predictions_smell_6delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    hh0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=0)\n",
    "        hh0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_hh-0delay'] = hh0_mses.mean()\n",
    "    predictions_hh_0delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    hh6_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=6)\n",
    "        hh6_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_hh-6delay'] = hh6_mses.mean()\n",
    "    predictions_hh_6delay[fips] = predicted_case\n",
    "    \n",
    "    naive_pred = case_ma7_all.loc[left-datetime.timedelta(days=7):right-datetime.timedelta(days=7)].copy()\n",
    "    naive_pred.index = shifted_range\n",
    "    county_data['naive'] = calc_mse(naive_pred.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \"\"\"\n",
    "    \n",
    "    df_index.append(fips)\n",
    "    err_data.append(county_data)\n",
    "    print('Complete with', fips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_fl_df = pd.DataFrame(err_data, index=df_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_fl_df.to_csv(r'output/err_fl_ihme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_case_only.to_csv(r'output/pred_fl_case_only.csv')\n",
    "predictions_smell_0delay.to_csv(r'output/pred_fl_smell_0delay.csv')\n",
    "predictions_smell_6delay.to_csv(r'output/pred_fl_smell_6delay.csv')\n",
    "predictions_hh_0delay.to_csv(r'output/pred_fl_hh_0delay.csv')\n",
    "predictions_hh_6delay.to_csv(r'output/pred_fl_hh_6delay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "county = 'Erie'\n",
    "state_2l = 'NY'\n",
    "if state_2l == 'NY':\n",
    "    the_seiir = seiir_ny\n",
    "else:\n",
    "    the_seiir = seiir_fl\n",
    "\n",
    "\n",
    "county_preds = {}\n",
    "survey_data = {}\n",
    "estimates = ['confirmed_only', 'hh_delay0', 'smell_delay0']\n",
    "measure_type = [None, 'hh', 'smell']\n",
    "#delay_list = [0, 0, 0]\n",
    "for i in range(len(estimates)):\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2l, county, the_seiir, smell_data, hh_data, case_data, measure=measure_type[i], K0=datetime.date(2020, 4, 18), delay=0)\n",
    "    survey_data[estimates[i]] = num_survey_ma7\n",
    "    county_preds[estimates[i]] = predicted_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate_type = ['hh_delay6', 'confirmed_only', 'hh_delay0', 'smell_delay0', 'smell_delay6']\n",
    "labels = ['Forecast using Case Count Only', 'Forecast Case Count w/ Household Symptoms', 'Forecast Case Count w/ Loss of Smell/Taste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of Cases per Day')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "d = datetime.date(2020, 10, 23)\n",
    "gold_right = d + datetime.timedelta(days=7)\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=K0, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i in range(len(estimates)):\n",
    "    plt.plot(county_preds[estimates[i]].index, county_preds[estimates[i]], label=labels[i], c=colors[i])\n",
    "plt.plot(case_ma7_all.loc[K0:gold_right].index, case_ma7_all.loc[K0:gold_right], label='Actual Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior, label='IHME Forecast', c=)\n",
    "\n",
    "\n",
    "#naieve estimate\n",
    "naive_start = K0 + datetime.timedelta(days=7)\n",
    "naive_d = d + datetime.timedelta(days=7)\n",
    "plt.plot(case_ma7_all.loc[naive_start:naive_d].index, case_ma7_all.loc[K0:d], label='Naive Estimate', c='orange')\n",
    "plt.legend(loc='upper center')\n",
    "plt.xticks(rotation=30, ha='right', rotation_mode='anchor')\n",
    "#plt.ylim(2700, 3055)\n",
    "#plt.xlim(datetime.date(2020, 7, 25), datetime.date(2020, 7, 30))\n",
    "\n",
    "\n",
    "#plt.title(county)\n",
    "plt.ylabel('Number of Cases per Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_vals.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K_vals.index, K_vals)\n",
    "plt.title('Miami-Dade hh6 K[4, 4] Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(case_ma7_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['test'] = predicted_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame()\n",
    "output_df[the_county] = predicted_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(r'output/predicted_case_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All plotting code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim_left = None\n",
    "xlim_right = None\n",
    "\n",
    "leftylim_low = None\n",
    "leftylim_high = None\n",
    "\n",
    "rightylim_low = None\n",
    "rightylim_high = None\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot findings -- multiple plots\n",
    "\n",
    "# Plotting constants and variables ----------------\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "purple = '#33016F'\n",
    "gold = '#9E7A27'\n",
    "gray = '#797979'\n",
    "width = 3\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=K0, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737517.0, 737711.0)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This is the one plot\n",
    "\n",
    "end = d + datetime.timedelta(days=7)\n",
    "d = datetime.date(2020, 10, 23)\n",
    "fig4, ax41 = plt.subplots(1)\n",
    "plt.sca(ax41)\n",
    "plt.plot(case_ma7_all.loc[K0:end].index, case_ma7_all.loc[K0:end], label='Actual Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "\n",
    "#naive estimate\n",
    "naive_start = K0 + datetime.timedelta(days=7)\n",
    "naive_d = d + datetime.timedelta(days=7)\n",
    "plt.plot(case_ma7_all.loc[naive_start:naive_d].index, case_ma7_all.loc[K0:d], label='Naive Estimate', c='orange')\n",
    "\n",
    "ax42 = ax41.twinx()\n",
    "plt.sca(ax42)\n",
    "plt.plot(survey_data['hh_delay0'].loc[K0:end].index, survey_data['hh_delay0'].loc[K0:end], c='red',\n",
    "         label='Count of Household Symptom Response', linewidth=width-1)\n",
    "plt.plot(survey_data['smell_delay0'].loc[K0:end].index, survey_data['smell_delay0'].loc[K0:end], c='maroon',\n",
    "         label='Count of Loss of Smell Response', linewidth=width-1)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Responses per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\n",
    "\n",
    "plt.sca(ax41)\n",
    "#plt.plot(predicted_case.index, predicted_case.loc[K0:], label='Our 7-Day Forecast',\n",
    "#         c=purple, linewidth=width)\n",
    "plt.plot(county_preds['confirmed_only'].index, county_preds['confirmed_only'], c=purple,\n",
    "         label='7-Day Forecast using Case Count Only', linewidth=width-1)\n",
    "plt.plot(county_preds['hh_delay0'].index, county_preds['hh_delay0'], c='cyan',\n",
    "         label='7-Day Forecast Case Count w/ Household Symptoms', linewidth=width-1)\n",
    "plt.plot(county_preds['smell_delay0'].index, county_preds['smell_delay0'], c='green',\n",
    "         label='7-Day Forecast Case Count w/ Loss of Smell/Taste', linewidth=width-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "#plt.title('Miami-Dade, Household Symptoms, delay of 6 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-04-25    3288.680918\n",
       "2020-04-26    3085.764595\n",
       "2020-04-27    2970.918546\n",
       "2020-04-28    2833.534226\n",
       "2020-04-29    2195.126925\n",
       "                 ...     \n",
       "2020-10-26     641.448294\n",
       "2020-10-27     620.286452\n",
       "2020-10-28     678.196336\n",
       "2020-10-29     682.448306\n",
       "2020-10-30     676.258395\n",
       "Length: 189, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_preds[estimates[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 4, 18)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC plot settings\n",
    "\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -480\n",
    "leftylim_high = 8000\n",
    "\n",
    "rightylim_low = -5\n",
    "rightylim_high = 85\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nassau plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -66\n",
    "leftylim_high = 1650\n",
    "\n",
    "rightylim_low = -.3\n",
    "rightylim_high = 8\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Westchester plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -28\n",
    "leftylim_high = 1000\n",
    "\n",
    "rightylim_low = -.5\n",
    "rightylim_high = 17\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albany plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -6\n",
    "leftylim_high = 120\n",
    "\n",
    "rightylim_low = -.125\n",
    "rightylim_high = 3.8\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erie plot settings\n",
    "xlim_left = datetime.date(2020, 4, 2)\n",
    "xlim_right = datetime.date(2020, 10, 13)\n",
    "\n",
    "leftylim_low = -10\n",
    "leftylim_high = 280\n",
    "\n",
    "rightylim_low = -.8\n",
    "rightylim_high = 22\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
