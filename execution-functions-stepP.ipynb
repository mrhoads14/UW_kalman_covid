{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs an extended Kalman filter using IHME SEIIR predictions along with measurement data of confirmed Covid-19 case counts (from New York Times data) and CMU/Facebook symptom data (from Covid-19 Symptom Challenge) to generate updated 7-day predictions of case counts for counties in New York State and Florida.\n",
    "\n",
    "Developed by the University of Washington team of Les Atlas, Abraham Flaxman and Michael Rhoads.\n",
    "\n",
    "S - Susceptible\n",
    "E - Exposed\n",
    "I1 - Presymptomatic\n",
    "I2 - Symptomatic\n",
    "R - Recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import data_sets\n",
    "import seiir_compartmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to support the Kalman filtering\n",
    "def get_predicts_prior(day, seiir):\n",
    "    x_hat = np.array([[seiir['S'].loc[day]],\n",
    "                      [seiir['E'].loc[day]],\n",
    "                      [seiir['I1'].loc[day]],\n",
    "                      [seiir['I2'].loc[day]],\n",
    "                      [seiir['R'].loc[day]]])\n",
    "\n",
    "    beta_k = seiir['beta'].loc[day]\n",
    "\n",
    "    return x_hat, beta_k\n",
    "\n",
    "\n",
    "def step_seiir(x_hat, constants, beta_k, days=7):\n",
    "    s_dict = {'S': x_hat[0, 0],\n",
    "              'E': x_hat[1, 0],\n",
    "              'I1': x_hat[2, 0],\n",
    "              'I2': x_hat[3, 0],\n",
    "              'R': x_hat[4, 0]}\n",
    "\n",
    "    s = pd.Series(s_dict)\n",
    "\n",
    "    for i in range(days):\n",
    "        infectious = s.loc['I1'] + s.loc['I2']\n",
    "        s = seiir_compartmental.compartmental_covid_step(s, s.sum(),\n",
    "                                                         infectious,\n",
    "                                                         constants['alpha'],\n",
    "                                                         beta_k,\n",
    "                                                         constants['gamma1'],\n",
    "                                                         constants['gamma2'],\n",
    "                                                         constants['sigma'],\n",
    "                                                         constants['theta'])\n",
    "    x_hat_future_prior = np.array([[s.loc['S']],\n",
    "                                   [s.loc['E']],\n",
    "                                   [s.loc['I1']],\n",
    "                                   [s.loc['I2']],\n",
    "                                   [s.loc['R']]])\n",
    "\n",
    "    return x_hat_future_prior\n",
    "\n",
    "\n",
    "def predict_step(x_hat_k1_prior, P, Q, beta_k, constants):\n",
    "    S = x_hat_k1_prior[0, 0]\n",
    "    E = x_hat_k1_prior[1, 0]\n",
    "    I1 = x_hat_k1_prior[2, 0]\n",
    "    I2 = x_hat_k1_prior[3, 0]\n",
    "    R = x_hat_k1_prior[4, 0]\n",
    "    N = S + E + I1 + I2 + R\n",
    "    alpha = constants['alpha']\n",
    "    sigma = constants['sigma']\n",
    "    gamma1 = constants['gamma1']\n",
    "    gamma2 = constants['gamma2']\n",
    "\n",
    "    part_f_S = np.array([[-beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [beta_k * math.pow(I1 + I2, alpha) / N],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_E = np.array([[0],\n",
    "                         [-sigma],\n",
    "                         [sigma],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    part_f_I1 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [-gamma1],\n",
    "                          [gamma1],\n",
    "                          [0]])\n",
    "\n",
    "    part_f_I2 = np.array([[-alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [alpha * beta_k * S * math.pow(I1+I2, alpha-1) / N],\n",
    "                          [0],\n",
    "                          [-gamma2],\n",
    "                          [gamma2]])\n",
    "    \n",
    "    part_f_R = np.array([[0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0],\n",
    "                         [0]])\n",
    "\n",
    "    # 5x5\n",
    "    f_jacob = np.concatenate([part_f_S, part_f_E, part_f_I1, part_f_I2,\n",
    "                              part_f_R], axis=1)\n",
    "\n",
    "\n",
    "    # 5x5\n",
    "    # P_prior = f_jacob * P * f_jacob^T + Q\n",
    "    P_prior = np.matmul(np.matmul(f_jacob, P), f_jacob.T) + Q\n",
    "    \n",
    "    return P_prior\n",
    "\n",
    "\n",
    "def update_step(x_hat, x_hat_k1, P_prior, Rn, rho1, rho2, z_k, measure):\n",
    "    # 5x5\n",
    "    ep = 10**-8\n",
    "    \n",
    "    # if there is no survey measurement used, then rho1 is not needed\n",
    "    if measure is None:\n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, 0, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    else:\n",
    "                \n",
    "        H = np.array([[ep, 0, 0, 0, 0],\n",
    "                      [0, ep, 0, 0, 0],\n",
    "                      [0, 0, ep, rho1, 0],\n",
    "                      [0, 0, 0, rho2, 0],\n",
    "                      [0, 0, 0, 0, ep]])\n",
    "    \n",
    "    \n",
    "    # Si = H * P_prior * H^T + Rn\n",
    "    Si = np.matmul(np.matmul(H, P_prior), H.T) + Rn\n",
    "\n",
    "    # K = P_prior * H.T (H * P_prior * H.T + R)^-1\n",
    "    # K_new = P_prior * H^T * Si^(-1)\n",
    "    K_new = np.matmul(np.matmul(P_prior, H.T), np.linalg.inv(Si))\n",
    "    \n",
    "    y_new = np.matmul(H, x_hat)\n",
    "\n",
    "    # 5x1\n",
    "    diff = z_k - y_new\n",
    "\n",
    "    x_hat_k1_post = x_hat_k1 + np.matmul(K_new, diff)\n",
    "\n",
    "    P_post = P_prior - np.matmul(np.matmul(K_new, Si), K_new.T)\n",
    "\n",
    "\n",
    "    return x_hat_k1_post, P_post, diff, K_new[3, 3]\n",
    "\n",
    "\n",
    "def create_data_sets():\n",
    "    seiir_fl = pd.read_csv(r'data/seiir_projections/florida_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "\n",
    "    seiir_ny = pd.read_csv(r'data/seiir_projections/new_york_proj.csv', header=0,\n",
    "                            index_col='date', parse_dates=True)\n",
    "    \n",
    "    smell_data = data_sets.create_symptom_df()\n",
    "    \n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    \n",
    "    return seiir_fl, seiir_ny, smell_data, case_data\n",
    "\n",
    "\n",
    "def get_smell_data(fips, fb_data):\n",
    "\n",
    "    if fips == 'New York City':\n",
    "        nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "        fb_data_geo = fb_data.loc[(slice(None), '36081'), :].copy()\n",
    "        fb_data_geo = fb_data_geo.mean(level='date')\n",
    "\n",
    "        for borough in nyc_fips:\n",
    "            fb_data_geo += fb_data.loc[(slice(None), borough), :].copy().mean(level='date')\n",
    "\n",
    "    else:\n",
    "        fb_data_geo = fb_data.loc[(slice(None), fips), :].copy()\n",
    "\n",
    "        # collapse down to a single index column (date)\n",
    "        fb_data_geo.index = fb_data_geo.index.droplevel([0, 1])\n",
    "\n",
    "    return fb_data_geo\n",
    "    \n",
    "\n",
    "\n",
    "def calc_fb_ma7(fb_data):\n",
    "    \"\"\"\n",
    "    Returns a Pandas series\n",
    "    \"\"\"\n",
    "    # the fb_data is a DataFrame while the case_data is a Series\n",
    "    fb_ma7 = fb_data.rolling(window=7).mean()\n",
    "    fb_ma7 = fb_ma7.iloc[6:, :]\n",
    "    prop_ma7 = fb_ma7['num_stl'].div(fb_ma7['n'])\n",
    "\n",
    "    return prop_ma7, fb_ma7['n'].copy(), fb_ma7['num_stl'].copy()\n",
    "\n",
    "\n",
    "def calc_mse(prediction, actual):\n",
    "    \"\"\"\n",
    "    Inputs should be two Pandas Series of same length.\n",
    "    Outputs a float.\n",
    "    \"\"\"\n",
    "    err = prediction - actual\n",
    "    sum_sq_err = (err**2).sum()\n",
    "    mse = sum_sq_err / err.count()\n",
    "    return mse\n",
    "\n",
    "\n",
    "def create_hh_data():\n",
    "    # bring in household covid symptom data\n",
    "    full_data = pd.read_csv(r'data/from_challenge/overall-county.csv', header=0, dtype={'fips': 'str', 'pct_hh_cli': 'float64'},\n",
    "                            parse_dates=[0])\n",
    "    time_start = full_data['date'].min()\n",
    "    time_end = full_data['date'].max()\n",
    "    full_data.set_index(['fips', 'date'], inplace=True)\n",
    "    full_data.sort_index(inplace=True)\n",
    "\n",
    "    # derive count of survey respondents with household members having covid symptoms\n",
    "    full_data['num_hh_cli'] = full_data['n'].mul(full_data['pct_hh_cli']/100.).round()\n",
    "    full_data['num_hh_cli'] = full_data['num_hh_cli'].astype('int64')\n",
    "\n",
    "    # group by county and date\n",
    "    data_of_interest = full_data[['n', 'num_hh_cli']].copy().groupby(level=(0, 1)).sum()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    # create full date range\n",
    "    date_rng = pd.date_range(time_start, time_end)\n",
    "    iterables = [data_of_interest.index.levels[0], date_rng]\n",
    "    new_index = pd.MultiIndex.from_product(iterables, names=['fips', 'date'])\n",
    "\n",
    "    data_of_interest = data_of_interest.reindex(index=new_index)\n",
    "    # this will have NaN values in the new index entries for which there was no\n",
    "    # previous data -- fill them upon extracting a particular county\n",
    "    \n",
    "    return data_of_interest\n",
    "\n",
    "\n",
    "def create_county_lists():\n",
    "    case_data = data_sets.create_case_df_county()\n",
    "    ny_counties = case_data[case_data['state'] == 'New York']['county'].unique()\n",
    "    fl_counties = case_data[case_data['state'] == 'Florida']['county'].unique()\n",
    "    return ny_counties, fl_counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data sets\n",
    "\n",
    "seiir_fl, seiir_ny, smell_data, case_data = create_data_sets()\n",
    "hh_data = create_hh_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_county(the_state, county_name, seiir, smell_data, hh_data, case_data, measure='smell', K0=datetime.date(2020, 4, 18), delay=6):\n",
    "    \"\"\"\n",
    "    The main function that calculates the forecast for a given county over the entire time range\n",
    "    Arguments:\n",
    "        measure -- potential values are: 'smell', 'hh', or None\n",
    "    \"\"\"\n",
    "    # set constants\n",
    "    #K0 = datetime.date(2020, 4, 12)\n",
    "\n",
    "    if county_name == 'New York City':\n",
    "        the_county = county_name\n",
    "    else:\n",
    "        the_county = data_sets.get_fips(the_state, county_name)\n",
    "\n",
    "    constants = {\n",
    "        'alpha': 0.948786,\n",
    "        'gamma1': 0.500000,\n",
    "        'gamma2': 0.662215,\n",
    "        'sigma': 0.266635,\n",
    "        'theta': 6.000000\n",
    "        }\n",
    "\n",
    "    # set initial values for Kalman filter parameters\n",
    "    P_mult = 1\n",
    "    Q_mult = 1\n",
    "\n",
    "    # Rn is the R noise covariance matrix; it remains constant thru the stepping of the\n",
    "    # Kalman filter\n",
    "    Rn_mult = 5*10**-8\n",
    "\n",
    "    Rn_22 = 10000\n",
    "    Rn_32 = 1000\n",
    "\n",
    "    Rn_23 = 1000\n",
    "    Rn_33 = 100\n",
    "\n",
    "    Rn = Rn_mult * np.array([[0, 0, 0, 0, 0],\n",
    "                             [0, 0, 0, 0, 0],\n",
    "                             [0, 0, Rn_22, Rn_23, 0],\n",
    "                             [0, 0, Rn_32, Rn_33, 0],\n",
    "                             [0, 0, 0, 0, 0]])\n",
    "\n",
    "    Q = Q_mult * np.eye(5)\n",
    "    P = P_mult * np.eye(5)\n",
    "    \n",
    "    if the_county == 'New York City':\n",
    "        county_pop = 0\n",
    "        for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "            this_count, state_pop = data_sets.get_pops(each)\n",
    "            county_pop += this_count\n",
    "    else:\n",
    "        county_pop, state_pop = data_sets.get_pops(the_county)\n",
    "\n",
    "    b = county_pop / state_pop\n",
    "\n",
    "    # generate data\n",
    "    case_data_geo = case_data.loc[the_county]['case_rate'].copy()\n",
    "    smell_data_geo = get_smell_data(the_county, smell_data)\n",
    "    \n",
    "\n",
    "    if measure == 'hh':\n",
    "        idx = pd.IndexSlice\n",
    "        \n",
    "        if the_county == 'New York City':\n",
    "            nyc_fips = ['36005', '36061', '36047', '36085']\n",
    "            hh_cli = hh_data.loc[idx['36081', :], :].loc['36081'].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "            for borough in nyc_fips:\n",
    "                bor_hh_cli = hh_data.loc[idx[borough, :], :].loc[borough].copy()\n",
    "                bor_hh_cli.fillna(method='pad', inplace=True)\n",
    "                hh_cli += bor_hh_cli\n",
    "\n",
    "        else:\n",
    "            hh_cli = hh_data.loc[idx[the_county, :], :].loc[the_county].copy()\n",
    "            hh_cli.fillna(method='pad', inplace=True)\n",
    "\n",
    "        # calculate moving averages on the fb and case data\n",
    "        hh_cli_ma7 = hh_cli.rolling(window=7).mean()\n",
    "        hh_cli_ma7 = hh_cli_ma7.iloc[6:, :]\n",
    "        num_survey_ma7 = hh_cli_ma7['num_hh_cli']\n",
    "        prop_cli_ma7 = num_survey_ma7.div(hh_cli_ma7['n'])\n",
    "        \n",
    "    elif measure == 'smell':\n",
    "        prop_ma7, n_ma7, num_survey_ma7 = calc_fb_ma7(smell_data_geo)\n",
    "        \n",
    "    else:\n",
    "        num_survey_ma7 = None\n",
    "\n",
    "\n",
    "    case_ma7 = case_data_geo.rolling(window=7).mean()\n",
    "    case_ma7_all = case_ma7.iloc[6:]\n",
    "    \n",
    "\n",
    "    # get starting compartment values for the state level\n",
    "    x_hat_state_k0, beta_k0 = get_predicts_prior(K0, seiir)\n",
    "\n",
    "    # convert to the county level\n",
    "    x_hat_k0 = b * x_hat_state_k0\n",
    "\n",
    "    I2_county = x_hat_k0[3, 0]\n",
    "\n",
    "\n",
    "    rho1 = .05\n",
    "    rho2 = case_ma7_all.loc['2020-04-12'] / I2_county\n",
    "\n",
    "\n",
    "    # create empty dictionaries to hold the estimated values\n",
    "    case_est = {}\n",
    "    seiir_pred = {}\n",
    "\n",
    "    diff_rat = {}\n",
    "\n",
    "    K_val_dict = {}\n",
    "\n",
    "\n",
    "    # Original data run ----------------\n",
    "    start = K0\n",
    "    k = start\n",
    "\n",
    "    while k <= datetime.date(2020, 10, 23):    \n",
    "\n",
    "    # each cycle of the while loop executes a step\n",
    "\n",
    "        # get state level compartments\n",
    "        x_hat_state_k, beta_k = get_predicts_prior(k, seiir)\n",
    "\n",
    "        # step the state level compartments 1 day forward\n",
    "        x_hat_state_k1 = step_seiir(x_hat_state_k, constants, beta_k, days=1)\n",
    "        P = predict_step(x_hat_state_k, P, Q, beta_k, constants)\n",
    "        \n",
    "        # then 6 more\n",
    "        P_est = P.copy()\n",
    "        for i in range(6):\n",
    "            x_hat_est = step_seiir(x_hat_state_k1, constants, beta_k, days=1)\n",
    "            P_est = predict_step(x_hat_state_k1, P_est, Q, beta_k, constants)\n",
    "            x_hat_state_k1 = x_hat_est.copy()\n",
    "\n",
    "        # convert the state level compartments to county level values\n",
    "        x_hat_k = b * x_hat_state_k\n",
    "        x_hat_k1 = b * x_hat_state_k1\n",
    "\n",
    "        \n",
    "        indexDate = k + datetime.timedelta(days=7)\n",
    "        # store seiir prediction before it's modified by Kalman filter\n",
    "        # multiply by rho2 to get values equivalent to confirmed case count\n",
    "        seiir_pred[indexDate] = rho2 * x_hat_k1[3, 0]\n",
    "\n",
    "        # get measurements for current day\n",
    "        if measure == 'smell':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_ma7.loc[k - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])    \n",
    "\n",
    "        elif measure == 'hh':\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [prop_cli_ma7.loc[k - datetime.timedelta(days=delay)]],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])\n",
    "            \n",
    "        else:\n",
    "            z_k = np.array([[0],\n",
    "                            [0],\n",
    "                            [0],\n",
    "                            [case_ma7_all.loc[k]],\n",
    "                            [0]])\n",
    "\n",
    "        # predict step using the stepped fwd SEIIR compartment values \n",
    "        #P = predict_step(x_hat_k1, P, Q, beta_k, constants)\n",
    "\n",
    "        # update step\n",
    "        x_hat_post, P_post, the_diff, K_val = update_step(x_hat_k, x_hat_k1, P_est, Rn,\n",
    "                                         rho1, rho2, z_k, measure)\n",
    "\n",
    "\n",
    "        # store estimated values for proportion and case rate\n",
    "        K_val_dict[indexDate] = K_val\n",
    "        case_est[indexDate] = rho2 * x_hat_post[3, 0]\n",
    "\n",
    "\n",
    "        diff_rat[indexDate] = the_diff[2, 0] / the_diff[3, 0]\n",
    "\n",
    "        # update the P and k\n",
    "        # comment out the P update because it has already been stepped once\n",
    "        #P = P_post\n",
    "        k += datetime.timedelta(days=1)\n",
    "\n",
    "    # create pandas series of the estimated case rate\n",
    "    predicted_case = pd.Series(case_est)\n",
    "    predicted_seiir_prior = pd.Series(seiir_pred)\n",
    "    K_val_series = pd.Series(K_val_dict)\n",
    "    \n",
    "    return predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_val_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single county run\n",
    "predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', 'New York City', seiir_ny, smell_data, hh_data, case_data, measure='smell', K0=datetime.date(2020, 4, 18), delay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "\n",
    "ny_counties, fl_counties = create_county_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast NY State counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_index = []\n",
    "err_data = []\n",
    "\n",
    "predictions_case_only = pd.DataFrame()\n",
    "predictions_smell_0delay = pd.DataFrame()\n",
    "predictions_hh_0delay = pd.DataFrame()\n",
    "\n",
    "\n",
    "left = K0 + datetime.timedelta(days=7)\n",
    "right = datetime.date(2020, 10, 23)\n",
    "shifted_range = pd.date_range(start=left, end=right)\n",
    "numLoop = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 36001\n",
      "Complete with 36001\n",
      "Starting 36007\n",
      "Complete with 36007\n",
      "Starting 36011\n",
      "Complete with 36011\n",
      "Starting 36013\n",
      "Complete with 36013\n",
      "Starting 36015\n",
      "Complete with 36015\n",
      "Starting 36019\n",
      "Complete with 36019\n",
      "Starting 36027\n",
      "Complete with 36027\n",
      "Starting 36029\n",
      "Complete with 36029\n",
      "Starting 36045\n",
      "Complete with 36045\n",
      "Starting 36053\n",
      "Complete with 36053\n",
      "Starting 36055\n",
      "Complete with 36055\n",
      "Starting 36059\n",
      "Complete with 36059\n",
      "Starting 36063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrhoa\\miniconda3\\envs\\covid_DOA\\lib\\site-packages\\ipykernel_launcher.py:183: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete with 36063\n",
      "Starting 36065\n",
      "Complete with 36065\n",
      "Starting 36067\n",
      "Complete with 36067\n",
      "Starting 36069\n",
      "Complete with 36069\n",
      "Starting 36071\n",
      "Complete with 36071\n",
      "Starting 36075\n",
      "Complete with 36075\n",
      "Starting 36083\n",
      "Complete with 36083\n",
      "Starting 36087\n",
      "Complete with 36087\n",
      "Starting 36089\n",
      "Complete with 36089\n",
      "Starting 36091\n",
      "Complete with 36091\n",
      "Starting 36093\n",
      "Complete with 36093\n",
      "Starting 36101\n",
      "Complete with 36101\n",
      "Starting 36103\n",
      "Complete with 36103\n",
      "Starting 36107\n",
      "Complete with 36107\n",
      "Starting 36109\n",
      "Complete with 36109\n",
      "Starting 36111\n",
      "Complete with 36111\n",
      "Starting 36117\n",
      "Complete with 36117\n",
      "Starting 36119\n",
      "Complete with 36119\n",
      "Starting New York City\n",
      "Complete with New York City\n"
     ]
    }
   ],
   "source": [
    "# conduct a forecast for all the counties in NY that there exists survey data for\n",
    "\n",
    "for each in ny_counties:\n",
    "    if each == 'New York City':\n",
    "        fips = 'New York City'\n",
    "    else:\n",
    "        fips = data_sets.get_fips('NY', each)\n",
    "        if (fips not in hh_data.index.levels[0]) or (fips not in smell_data.index.levels[1]):\n",
    "            continue\n",
    "    \n",
    "    print('Starting', fips)\n",
    "    \n",
    "    county_data = {}\n",
    "    \n",
    "    conf_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure=None, K0=K0, delay=0)\n",
    "        conf_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_confirmed-only'] = conf_mses.mean()\n",
    "    predictions_case_only[fips] = predicted_case\n",
    "    \n",
    "    \n",
    "    smell0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=0)\n",
    "        smell0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_smell-0delay'] = smell0_mses.mean()\n",
    "    predictions_smell_0delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    hh0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county('NY', each, seiir_ny, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=0)\n",
    "        hh0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_hh-0delay'] = hh0_mses.mean()\n",
    "    predictions_hh_0delay[fips] = predicted_case\n",
    "    \n",
    "    \n",
    "    naive_pred = case_ma7_all.loc[left-datetime.timedelta(days=7):right-datetime.timedelta(days=7)].copy()\n",
    "    naive_pred.index = shifted_range\n",
    "    county_data['naive'] = calc_mse(naive_pred.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \n",
    "    county_data['ihme'] = calc_mse(predicted_seiir_prior.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \n",
    "    df_index.append(fips)\n",
    "    err_data.append(county_data)\n",
    "    print('Complete with', fips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_ny_df = pd.DataFrame(err_data, index=df_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse_confirmed-only</th>\n",
       "      <th>mse_smell-0delay</th>\n",
       "      <th>mse_hh-0delay</th>\n",
       "      <th>naive</th>\n",
       "      <th>ihme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>63.181190</td>\n",
       "      <td>140.064984</td>\n",
       "      <td>138.630141</td>\n",
       "      <td>58.118188</td>\n",
       "      <td>204.685166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36007</th>\n",
       "      <td>83.426388</td>\n",
       "      <td>957.571617</td>\n",
       "      <td>943.858539</td>\n",
       "      <td>82.950437</td>\n",
       "      <td>571.845814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36011</th>\n",
       "      <td>1.774223</td>\n",
       "      <td>5.642487</td>\n",
       "      <td>5.543090</td>\n",
       "      <td>1.698924</td>\n",
       "      <td>4.261771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36013</th>\n",
       "      <td>11.005737</td>\n",
       "      <td>97.318431</td>\n",
       "      <td>102.784913</td>\n",
       "      <td>10.963220</td>\n",
       "      <td>36.294082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36015</th>\n",
       "      <td>27.170071</td>\n",
       "      <td>455.333062</td>\n",
       "      <td>453.070886</td>\n",
       "      <td>27.059542</td>\n",
       "      <td>213.868281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36019</th>\n",
       "      <td>0.802063</td>\n",
       "      <td>12.485686</td>\n",
       "      <td>12.318862</td>\n",
       "      <td>0.778762</td>\n",
       "      <td>1.395856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36027</th>\n",
       "      <td>111.574655</td>\n",
       "      <td>102.871271</td>\n",
       "      <td>101.513815</td>\n",
       "      <td>74.615609</td>\n",
       "      <td>50.905489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36029</th>\n",
       "      <td>340.211610</td>\n",
       "      <td>1118.723716</td>\n",
       "      <td>1118.924772</td>\n",
       "      <td>278.860170</td>\n",
       "      <td>2671.435429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36045</th>\n",
       "      <td>0.469671</td>\n",
       "      <td>435.868828</td>\n",
       "      <td>432.047918</td>\n",
       "      <td>0.443709</td>\n",
       "      <td>0.748027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36053</th>\n",
       "      <td>13.830569</td>\n",
       "      <td>15010.506211</td>\n",
       "      <td>13200.424153</td>\n",
       "      <td>13.627719</td>\n",
       "      <td>11.807451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36055</th>\n",
       "      <td>113.347459</td>\n",
       "      <td>1333.154730</td>\n",
       "      <td>1313.935970</td>\n",
       "      <td>99.655304</td>\n",
       "      <td>877.356332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36059</th>\n",
       "      <td>1788.384909</td>\n",
       "      <td>1527.251911</td>\n",
       "      <td>1502.944027</td>\n",
       "      <td>5922.782126</td>\n",
       "      <td>8713.228232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36063</th>\n",
       "      <td>13.955016</td>\n",
       "      <td>190.843251</td>\n",
       "      <td>188.878869</td>\n",
       "      <td>11.859610</td>\n",
       "      <td>93.493502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36065</th>\n",
       "      <td>27.973290</td>\n",
       "      <td>104.176372</td>\n",
       "      <td>102.483719</td>\n",
       "      <td>23.952456</td>\n",
       "      <td>159.341745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36067</th>\n",
       "      <td>78.366356</td>\n",
       "      <td>4490.759803</td>\n",
       "      <td>4439.537851</td>\n",
       "      <td>75.050684</td>\n",
       "      <td>702.848842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36069</th>\n",
       "      <td>3.556799</td>\n",
       "      <td>377.760561</td>\n",
       "      <td>372.871791</td>\n",
       "      <td>3.450998</td>\n",
       "      <td>10.577846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36071</th>\n",
       "      <td>1344.968066</td>\n",
       "      <td>1360.281706</td>\n",
       "      <td>1337.289299</td>\n",
       "      <td>1225.038686</td>\n",
       "      <td>603.100966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36075</th>\n",
       "      <td>4.248439</td>\n",
       "      <td>36.725318</td>\n",
       "      <td>36.917759</td>\n",
       "      <td>4.237834</td>\n",
       "      <td>14.328768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36083</th>\n",
       "      <td>6.371333</td>\n",
       "      <td>2253.989363</td>\n",
       "      <td>2228.428666</td>\n",
       "      <td>6.258354</td>\n",
       "      <td>24.977110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36087</th>\n",
       "      <td>1752.568312</td>\n",
       "      <td>1772.754757</td>\n",
       "      <td>1742.498735</td>\n",
       "      <td>1699.676497</td>\n",
       "      <td>1422.372873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36089</th>\n",
       "      <td>2.481482</td>\n",
       "      <td>29.822634</td>\n",
       "      <td>29.869371</td>\n",
       "      <td>2.537789</td>\n",
       "      <td>2.263435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36091</th>\n",
       "      <td>6.857178</td>\n",
       "      <td>863.443692</td>\n",
       "      <td>853.977189</td>\n",
       "      <td>6.675488</td>\n",
       "      <td>27.009991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36093</th>\n",
       "      <td>36.432203</td>\n",
       "      <td>79.733037</td>\n",
       "      <td>79.670946</td>\n",
       "      <td>34.981498</td>\n",
       "      <td>49.307331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36101</th>\n",
       "      <td>7.520558</td>\n",
       "      <td>9.409466</td>\n",
       "      <td>9.349661</td>\n",
       "      <td>7.403005</td>\n",
       "      <td>57.260765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36103</th>\n",
       "      <td>1416.359090</td>\n",
       "      <td>1212.428755</td>\n",
       "      <td>1191.277361</td>\n",
       "      <td>5701.843575</td>\n",
       "      <td>1987.043144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36107</th>\n",
       "      <td>3.798108</td>\n",
       "      <td>88.996438</td>\n",
       "      <td>88.430351</td>\n",
       "      <td>3.765194</td>\n",
       "      <td>16.178982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36109</th>\n",
       "      <td>4.185034</td>\n",
       "      <td>202.779533</td>\n",
       "      <td>227.008025</td>\n",
       "      <td>4.171787</td>\n",
       "      <td>12.265161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36111</th>\n",
       "      <td>59.876336</td>\n",
       "      <td>67.701200</td>\n",
       "      <td>66.712537</td>\n",
       "      <td>58.650594</td>\n",
       "      <td>48.022749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36117</th>\n",
       "      <td>1.225651</td>\n",
       "      <td>30.303063</td>\n",
       "      <td>30.406895</td>\n",
       "      <td>1.188047</td>\n",
       "      <td>3.939067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36119</th>\n",
       "      <td>647.707208</td>\n",
       "      <td>565.710109</td>\n",
       "      <td>559.634037</td>\n",
       "      <td>3136.134896</td>\n",
       "      <td>761.028801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York City</th>\n",
       "      <td>30420.125404</td>\n",
       "      <td>24430.316355</td>\n",
       "      <td>24175.021695</td>\n",
       "      <td>122775.416125</td>\n",
       "      <td>33655.681345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mse_confirmed-only  mse_smell-0delay  mse_hh-0delay  \\\n",
       "36001                   63.181190        140.064984     138.630141   \n",
       "36007                   83.426388        957.571617     943.858539   \n",
       "36011                    1.774223          5.642487       5.543090   \n",
       "36013                   11.005737         97.318431     102.784913   \n",
       "36015                   27.170071        455.333062     453.070886   \n",
       "36019                    0.802063         12.485686      12.318862   \n",
       "36027                  111.574655        102.871271     101.513815   \n",
       "36029                  340.211610       1118.723716    1118.924772   \n",
       "36045                    0.469671        435.868828     432.047918   \n",
       "36053                   13.830569      15010.506211   13200.424153   \n",
       "36055                  113.347459       1333.154730    1313.935970   \n",
       "36059                 1788.384909       1527.251911    1502.944027   \n",
       "36063                   13.955016        190.843251     188.878869   \n",
       "36065                   27.973290        104.176372     102.483719   \n",
       "36067                   78.366356       4490.759803    4439.537851   \n",
       "36069                    3.556799        377.760561     372.871791   \n",
       "36071                 1344.968066       1360.281706    1337.289299   \n",
       "36075                    4.248439         36.725318      36.917759   \n",
       "36083                    6.371333       2253.989363    2228.428666   \n",
       "36087                 1752.568312       1772.754757    1742.498735   \n",
       "36089                    2.481482         29.822634      29.869371   \n",
       "36091                    6.857178        863.443692     853.977189   \n",
       "36093                   36.432203         79.733037      79.670946   \n",
       "36101                    7.520558          9.409466       9.349661   \n",
       "36103                 1416.359090       1212.428755    1191.277361   \n",
       "36107                    3.798108         88.996438      88.430351   \n",
       "36109                    4.185034        202.779533     227.008025   \n",
       "36111                   59.876336         67.701200      66.712537   \n",
       "36117                    1.225651         30.303063      30.406895   \n",
       "36119                  647.707208        565.710109     559.634037   \n",
       "New York City        30420.125404      24430.316355   24175.021695   \n",
       "\n",
       "                       naive          ihme  \n",
       "36001              58.118188    204.685166  \n",
       "36007              82.950437    571.845814  \n",
       "36011               1.698924      4.261771  \n",
       "36013              10.963220     36.294082  \n",
       "36015              27.059542    213.868281  \n",
       "36019               0.778762      1.395856  \n",
       "36027              74.615609     50.905489  \n",
       "36029             278.860170   2671.435429  \n",
       "36045               0.443709      0.748027  \n",
       "36053              13.627719     11.807451  \n",
       "36055              99.655304    877.356332  \n",
       "36059            5922.782126   8713.228232  \n",
       "36063              11.859610     93.493502  \n",
       "36065              23.952456    159.341745  \n",
       "36067              75.050684    702.848842  \n",
       "36069               3.450998     10.577846  \n",
       "36071            1225.038686    603.100966  \n",
       "36075               4.237834     14.328768  \n",
       "36083               6.258354     24.977110  \n",
       "36087            1699.676497   1422.372873  \n",
       "36089               2.537789      2.263435  \n",
       "36091               6.675488     27.009991  \n",
       "36093              34.981498     49.307331  \n",
       "36101               7.403005     57.260765  \n",
       "36103            5701.843575   1987.043144  \n",
       "36107               3.765194     16.178982  \n",
       "36109               4.171787     12.265161  \n",
       "36111              58.650594     48.022749  \n",
       "36117               1.188047      3.939067  \n",
       "36119            3136.134896    761.028801  \n",
       "New York City  122775.416125  33655.681345  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_ny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put error metrics in dataframe and output to .csv\n",
    "\n",
    "err_ny_df.to_csv(r'output/err_ny_20201023.csv')\n",
    "\n",
    "# output the dataframe of each type of estimate to .csvs\n",
    "predictions_case_only.to_csv(r'output/pred_ny_case_only.csv')\n",
    "predictions_smell_0delay.to_csv(r'output/pred_ny_smell_0delay.csv')\n",
    "predictions_hh_0delay.to_csv(r'output/pred_ny_hh_0delay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Florida counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = []\n",
    "err_data = []\n",
    "\n",
    "predictions_case_only = pd.DataFrame()\n",
    "predictions_smell_0delay = pd.DataFrame()\n",
    "predictions_hh_0delay = pd.DataFrame()\n",
    "\n",
    "left = K0 + datetime.timedelta(days=7)\n",
    "right = datetime.date(2020, 10, 23)\n",
    "shifted_range = pd.date_range(start=left, end=right)\n",
    "numLoop = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 12001\n",
      "Complete with 12001\n",
      "Starting 12005\n",
      "Complete with 12005\n",
      "Starting 12009\n",
      "Complete with 12009\n",
      "Starting 12011\n",
      "Complete with 12011\n",
      "Starting 12015\n",
      "Complete with 12015\n",
      "Starting 12017\n",
      "Complete with 12017\n",
      "Starting 12019\n",
      "Complete with 12019\n",
      "Starting 12021\n",
      "Complete with 12021\n",
      "Starting 12031\n",
      "Complete with 12031\n",
      "Starting 12033\n",
      "Complete with 12033\n",
      "Starting 12035\n",
      "Complete with 12035\n",
      "Starting 12053\n",
      "Complete with 12053\n",
      "Starting 12057\n",
      "Complete with 12057\n",
      "Starting 12061\n",
      "Complete with 12061\n",
      "Starting 12069\n",
      "Complete with 12069\n",
      "Starting 12071\n",
      "Complete with 12071\n",
      "Starting 12073\n",
      "Complete with 12073\n",
      "Starting 12081\n",
      "Complete with 12081\n",
      "Starting 12083\n",
      "Complete with 12083\n",
      "Starting 12085\n",
      "Complete with 12085\n",
      "Starting 12086\n",
      "Complete with 12086\n",
      "Starting 12091\n",
      "Complete with 12091\n",
      "Starting 12095\n",
      "Complete with 12095\n",
      "Starting 12097\n",
      "Complete with 12097\n",
      "Starting 12099\n",
      "Complete with 12099\n",
      "Starting 12101\n",
      "Complete with 12101\n",
      "Starting 12103\n",
      "Complete with 12103\n",
      "Starting 12105\n",
      "Complete with 12105\n",
      "Starting 12109\n",
      "Complete with 12109\n",
      "Starting 12111\n",
      "Complete with 12111\n",
      "Starting 12113\n",
      "Complete with 12113\n",
      "Starting 12115\n",
      "Complete with 12115\n",
      "Starting 12117\n",
      "Complete with 12117\n",
      "Starting 12127\n",
      "Complete with 12127\n"
     ]
    }
   ],
   "source": [
    "state_2L = 'FL'\n",
    "\n",
    "for each in fl_counties:\n",
    "    fips = data_sets.get_fips(state_2L, each)\n",
    "    if (fips not in hh_data.index.levels[0]) or (fips not in smell_data.index.levels[1]):\n",
    "        continue\n",
    "    \n",
    "    print('Starting', fips)\n",
    "    \n",
    "    county_data = {}\n",
    "    \n",
    "    conf_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure=None, K0=K0, delay=0)\n",
    "        conf_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \n",
    "    county_data['mse_confirmed-only'] = conf_mses.mean()\n",
    "    predictions_case_only[fips] = predicted_case\n",
    "    \n",
    "    \n",
    "    smell0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure='smell', K0=K0, delay=0)\n",
    "        smell0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_smell-0delay'] = smell0_mses.mean()\n",
    "    predictions_smell_0delay[fips] = predicted_case\n",
    "    \n",
    "\n",
    "    hh0_mses = np.zeros(numLoop)\n",
    "    for i in range(numLoop):\n",
    "        predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2L, each, seiir_fl, smell_data, hh_data, case_data, measure='hh', K0=K0, delay=0)\n",
    "        hh0_mses[i] = calc_mse(predicted_case.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    county_data['mse_hh-0delay'] = hh0_mses.mean()\n",
    "    predictions_hh_0delay[fips] = predicted_case\n",
    "    \n",
    "    \n",
    "    naive_pred = case_ma7_all.loc[left-datetime.timedelta(days=7):right-datetime.timedelta(days=7)].copy()\n",
    "    naive_pred.index = shifted_range\n",
    "    county_data['naive'] = calc_mse(naive_pred.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \n",
    "    county_data['ihme'] = calc_mse(predicted_seiir_prior.loc[left:right], case_ma7_all.loc[left:right])\n",
    "    \n",
    "    \n",
    "    df_index.append(fips)\n",
    "    err_data.append(county_data)\n",
    "    print('Complete with', fips)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_fl_df = pd.DataFrame(err_data, index=df_index)\n",
    "err_fl_df.to_csv(r'output/err_fl_20201023.csv')\n",
    "\n",
    "predictions_case_only.to_csv(r'output/pred_fl_case_only.csv')\n",
    "predictions_smell_0delay.to_csv(r'output/pred_fl_smell_0delay.csv')\n",
    "predictions_hh_0delay.to_csv(r'output/pred_fl_hh_0delay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All plotting code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "county = 'Westchester'\n",
    "state_2l = 'NY'\n",
    "if state_2l == 'NY':\n",
    "    the_seiir = seiir_ny\n",
    "else:\n",
    "    the_seiir = seiir_fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "if county == 'New York City':\n",
    "    county_pop = 0\n",
    "    for each in ['36081', '36005', '36061', '36047', '36085']:\n",
    "        this_count, state_pop = data_sets.get_pops(each)\n",
    "        county_pop += this_count\n",
    "else:\n",
    "    county_pop, state_pop = data_sets.get_pops(data_sets.get_fips(state_2l, county))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967506"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19453561"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "county_preds = {}\n",
    "survey_data = {}\n",
    "estimates = ['confirmed_only', 'hh_delay0', 'smell_delay0']\n",
    "measure_type = [None, 'hh', 'smell']\n",
    "#delay_list = [0, 0, 0]\n",
    "for i in range(len(estimates)):\n",
    "    predicted_case, predicted_seiir_prior, case_ma7_all, num_survey_ma7, K_vals = run_county(state_2l, county, the_seiir, smell_data, hh_data, case_data, measure=measure_type[i], K0=datetime.date(2020, 4, 18), delay=0)\n",
    "    survey_data[estimates[i]] = num_survey_ma7\n",
    "    county_preds[estimates[i]] = predicted_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate_type = ['hh_delay6', 'confirmed_only', 'hh_delay0', 'smell_delay0', 'smell_delay6']\n",
    "labels = ['Forecast using Case Count Only', 'Forecast Case Count w/ Household Symptoms', 'Forecast Case Count w/ Loss of Smell/Taste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0 = datetime.date(2020, 4, 18)\n",
    "d = datetime.date(2020, 10, 23)\n",
    "gold_right = d + datetime.timedelta(days=7)\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=K0, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i in range(len(estimates)):\n",
    "    plt.plot(county_preds[estimates[i]].index, county_preds[estimates[i]], label=labels[i], c=colors[i])\n",
    "plt.plot(case_ma7_all.loc[K0:gold_right].index, case_ma7_all.loc[K0:gold_right], label='Actual Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior, label='IHME Forecast', c=)\n",
    "\n",
    "\n",
    "#naieve estimate\n",
    "naive_start = K0 + datetime.timedelta(days=7)\n",
    "naive_d = d + datetime.timedelta(days=7)\n",
    "plt.plot(case_ma7_all.loc[naive_start:naive_d].index, case_ma7_all.loc[K0:d], label='Naive Estimate', c='orange')\n",
    "plt.legend(loc='upper center')\n",
    "plt.xticks(rotation=30, ha='right', rotation_mode='anchor')\n",
    "#plt.ylim(2700, 3055)\n",
    "#plt.xlim(datetime.date(2020, 7, 25), datetime.date(2020, 7, 30))\n",
    "\n",
    "\n",
    "#plt.title(county)\n",
    "plt.ylabel('Number of Cases per Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_vals.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K_vals.index, K_vals)\n",
    "plt.title('Miami-Dade hh6 K[4, 4] Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim_left = None\n",
    "xlim_right = None\n",
    "\n",
    "leftylim_low = None\n",
    "leftylim_high = None\n",
    "\n",
    "rightylim_low = None\n",
    "rightylim_high = None\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot findings -- multiple plots\n",
    "\n",
    "# Plotting constants and variables ----------------\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "purple = '#33016F'\n",
    "gold = '#9E7A27'\n",
    "gray = '#797979'\n",
    "width = 3\n",
    "%matplotlib qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = datetime.date(2020, 10, 23)\n",
    "K0 = datetime.date(2020, 4, 18)\n",
    "tick_end = predicted_seiir_prior.index[-1]\n",
    "\n",
    "week_interval = pd.date_range(start=K0, end=tick_end, freq='W')\n",
    "week_interval = [x.to_pydatetime().date() for x in week_interval]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_interval = pd.date_range(start=K0, end=tick_end, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737523.25, 737737.75)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This is the one plot\n",
    "\n",
    "end = d + datetime.timedelta(days=7)\n",
    "d = datetime.date(2020, 10, 23)\n",
    "fig4, ax41 = plt.subplots(1)\n",
    "plt.sca(ax41)\n",
    "plt.plot(case_ma7_all.loc[K0:end].index, case_ma7_all.loc[K0:end], label='Actual Case Count', c=gold,\n",
    "         linewidth=width)\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "\n",
    "#naive estimate\n",
    "naive_start = K0 + datetime.timedelta(days=7)\n",
    "naive_d = d + datetime.timedelta(days=7)\n",
    "plt.plot(case_ma7_all.loc[naive_start:naive_d].index, case_ma7_all.loc[K0:d], label='Naive Estimate', c='orange')\n",
    "\n",
    "\"\"\"\n",
    "ax42 = ax41.twinx()\n",
    "plt.sca(ax42)\n",
    "plt.plot(survey_data['hh_delay0'].loc[K0:end].index, survey_data['hh_delay0'].loc[K0:end], c='red',\n",
    "         label='Count of Household Symptom Response', linewidth=width-1)\n",
    "plt.plot(survey_data['smell_delay0'].loc[K0:end].index, survey_data['smell_delay0'].loc[K0:end], c='maroon',\n",
    "         label='Count of Loss of Smell Response', linewidth=width-1)\n",
    "plt.grid(axis='y', linestyle=':')\n",
    "\n",
    "plt.ylabel('Number of Responses per Day')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(rightylim_low, rightylim_high)\n",
    "\"\"\"\n",
    "\n",
    "#plt.sca(ax41)\n",
    "\"\"\"\n",
    "plt.plot(predicted_case.index, predicted_case.loc[K0:], label='Our 7-Day Forecast',\n",
    "         c=purple, linewidth=width)\n",
    "\"\"\"\n",
    "plt.plot(county_preds['confirmed_only'].index, county_preds['confirmed_only'], c=purple,\n",
    "         label='7-Day Forecast using Case Count Only', linewidth=width-1)\n",
    "plt.plot(county_preds['hh_delay0'].index, county_preds['hh_delay0'], c='cyan',\n",
    "         label='7-Day Forecast Case Count w/ Household Symptoms', linewidth=width-1)\n",
    "plt.plot(county_preds['smell_delay0'].index, county_preds['smell_delay0'], c='green',\n",
    "         label='7-Day Forecast Case Count w/ Loss of Smell/Taste', linewidth=width-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(week_interval, rotation=30, ha='right', rotation_mode='anchor', fontsize=xtick_size)\n",
    "plt.ylabel('Number of Cases per Day')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(leftylim_low, leftylim_high)\n",
    "plt.xlim(xlim_left, xlim_right)\n",
    "\n",
    "#plt.title('Miami-Dade, Household Symptoms, delay of 6 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_preds[estimates[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihme_ny_state = pd.read_csv(r'data/seiir_projections/new_york_proj.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>E</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>R</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-10</th>\n",
       "      <td>1.979023e+07</td>\n",
       "      <td>106.854381</td>\n",
       "      <td>25.532244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-11</th>\n",
       "      <td>1.979019e+07</td>\n",
       "      <td>135.370375</td>\n",
       "      <td>34.165081</td>\n",
       "      <td>5.735700</td>\n",
       "      <td>1.868136e+00</td>\n",
       "      <td>3.828568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-12</th>\n",
       "      <td>1.979014e+07</td>\n",
       "      <td>163.677532</td>\n",
       "      <td>44.895678</td>\n",
       "      <td>12.645587</td>\n",
       "      <td>6.414865e+00</td>\n",
       "      <td>3.065767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-13</th>\n",
       "      <td>1.979009e+07</td>\n",
       "      <td>185.941663</td>\n",
       "      <td>55.374704</td>\n",
       "      <td>20.009029</td>\n",
       "      <td>1.385817e+01</td>\n",
       "      <td>2.621240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-14</th>\n",
       "      <td>1.979004e+07</td>\n",
       "      <td>209.578200</td>\n",
       "      <td>66.865630</td>\n",
       "      <td>28.139395</td>\n",
       "      <td>2.479945e+01</td>\n",
       "      <td>2.268072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>1.258239e+07</td>\n",
       "      <td>6212.135951</td>\n",
       "      <td>3087.113438</td>\n",
       "      <td>2385.406004</td>\n",
       "      <td>7.196296e+06</td>\n",
       "      <td>0.872742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>1.258052e+07</td>\n",
       "      <td>6413.925937</td>\n",
       "      <td>3187.020352</td>\n",
       "      <td>2464.107692</td>\n",
       "      <td>7.197785e+06</td>\n",
       "      <td>0.874872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>1.257859e+07</td>\n",
       "      <td>6622.087015</td>\n",
       "      <td>3290.015767</td>\n",
       "      <td>2545.245365</td>\n",
       "      <td>7.199323e+06</td>\n",
       "      <td>0.876996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>1.257659e+07</td>\n",
       "      <td>6836.762379</td>\n",
       "      <td>3396.203136</td>\n",
       "      <td>2628.918289</td>\n",
       "      <td>7.200911e+06</td>\n",
       "      <td>0.879116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>1.257454e+07</td>\n",
       "      <td>7057.146142</td>\n",
       "      <td>3505.600545</td>\n",
       "      <td>2715.210083</td>\n",
       "      <td>7.202550e+06</td>\n",
       "      <td>0.880329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       S            E           I1           I2             R  \\\n",
       "date                                                                            \n",
       "2020-02-10  1.979023e+07   106.854381    25.532244     0.000000  0.000000e+00   \n",
       "2020-02-11  1.979019e+07   135.370375    34.165081     5.735700  1.868136e+00   \n",
       "2020-02-12  1.979014e+07   163.677532    44.895678    12.645587  6.414865e+00   \n",
       "2020-02-13  1.979009e+07   185.941663    55.374704    20.009029  1.385817e+01   \n",
       "2020-02-14  1.979004e+07   209.578200    66.865630    28.139395  2.479945e+01   \n",
       "...                  ...          ...          ...          ...           ...   \n",
       "2021-12-27  1.258239e+07  6212.135951  3087.113438  2385.406004  7.196296e+06   \n",
       "2021-12-28  1.258052e+07  6413.925937  3187.020352  2464.107692  7.197785e+06   \n",
       "2021-12-29  1.257859e+07  6622.087015  3290.015767  2545.245365  7.199323e+06   \n",
       "2021-12-30  1.257659e+07  6836.762379  3396.203136  2628.918289  7.200911e+06   \n",
       "2021-12-31  1.257454e+07  7057.146142  3505.600545  2715.210083  7.202550e+06   \n",
       "\n",
       "                beta  \n",
       "date                  \n",
       "2020-02-10  5.000033  \n",
       "2020-02-11  3.828568  \n",
       "2020-02-12  3.065767  \n",
       "2020-02-13  2.621240  \n",
       "2020-02-14  2.268072  \n",
       "...              ...  \n",
       "2021-12-27  0.872742  \n",
       "2021-12-28  0.874872  \n",
       "2021-12-29  0.876996  \n",
       "2021-12-30  0.879116  \n",
       "2021-12-31  0.880329  \n",
       "\n",
       "[691 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihme_ny_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d00b276ac8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_start = predicted_seiir_prior.index[0]\n",
    "gray_end = predicted_seiir_prior.index[-1]\n",
    "plt.plot(predicted_seiir_prior.index, predicted_seiir_prior,\n",
    "         label='IHME 7-day Forecast', c=gray, linewidth=width)\n",
    "plt.plot(ihme_ny_state.loc[gray_start:gray_end].index, ihme_ny_state['I2'].loc[gray_start:gray_end],\n",
    "         label='IHME State I2')\n",
    "plt.title('Nassau, b = 0.06975')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC plot settings\n",
    "\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -400\n",
    "leftylim_high = 7500\n",
    "\n",
    "rightylim_low = -3\n",
    "rightylim_high = 57\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nassau plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -66\n",
    "leftylim_high = 1000\n",
    "\n",
    "rightylim_low = -.3\n",
    "rightylim_high = 8\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Westchester plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -28\n",
    "leftylim_high = 700\n",
    "\n",
    "rightylim_low = -.5\n",
    "rightylim_high = 17\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albany plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -6\n",
    "leftylim_high = 110\n",
    "\n",
    "rightylim_low = -.125\n",
    "rightylim_high = 3.8\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erie plot settings\n",
    "xlim_left = datetime.date(2020, 4, 12)\n",
    "xlim_right = datetime.date(2020, 11, 3)\n",
    "\n",
    "leftylim_low = -10\n",
    "leftylim_high = 280\n",
    "\n",
    "rightylim_low = -.8\n",
    "rightylim_high = 22\n",
    "\n",
    "xtick_size = 14\n",
    "xlabel_size = 14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
